---
title: 'Problem Set 04'
author: "Your Name Here: Group X"
date: 'Last updated: `r Sys.Date()`'
output:
  html_document:
    smart: no
    theme: flatly
    toc: true
    toc_float: true
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(cowplot)
theme_set(theme_cowplot())
```


## Combining probabilities

Among a hypothetical population, blood type probabilities for all the combinations of AB antigens and Rh status:

|Type |Probability|
|-----|-----------|
| O+  |     0.39  |
| O-  |     0.01  |
| A+  |     0.27  |
| A-  |     0.005 |
| B+  |     0.25  |
| B-  |     0.004 |
| AB+ |     0.07  |
| AB- |     0.001 |

### Activity

What are the probabilities that a randomly selected individual has:

a. Type A+ blood

> 0.27

b. Type O blood

> 0.39 + 0.01 = 0.40

c. Type AB blood

> 0.07 + 0.001 = 0.071

d. *Not* Type AB blood

> 1 - 0.071 = 0.929

e. Type A *or* type B blood

> 0.27 + 0.005 + 0.25 + 0.004 = 0.529

f. Rh+ blood

> 0.39 + 0.27 + 0.25 + 0.07 = 0.98

## PSA

Elevated prostate-specific antigen (PSA) can indicate prostate cancer but can also result from other conditions unrelated to cancer. As with most medical tests, the PSA blood test, which is used as a screen for prostate cancer, is not 100% accurate. 4% of men over 65 have prostate cancer. When cancer is present, the test is positive 75% of the time. When cancer is absent, the test is positive in 7% of tests.

### Activity

What is the probability that randomly tested man over 65 has prostate cancer, given that they have received a positive PSA test? Solve this problem however you would like.

You are trying to find $Pr[Ca|Positive~Test]$.

### FIXME

#### Via Bayes' Rule

$$Pr[Ca|Positive~Test] = \frac{Pr[Positive~Test|Ca] \times Pr[Ca]}{Pr[Positive~Test]}$$

- $Pr[Positive~Test|Ca] = 0.75$
- $Pr[Ca] = 0.04$
- $Pr[Positive~Test] = 0.75 \times 0.04 + (1 - 0.04) \times 0.07$

so

```{r}
Ca_rate <- 0.04
True_pos <- 0.75
False_pos <- 0.07
(True_pos * Ca_rate) / (True_pos * Ca_rate + (1 - Ca_rate) * False_pos)
```

#### Or intuitively using an arbitrary number of tests

Assume that you carry out 1,000 tests.

- Total men with cancer: 1000 $\times$ 0.04 = 40
- Total men with no cancer: 1000 $\times$ (1 âˆ’ 0.04) = 960
- Positive tests among cancer group: 40 $\times$ 0.75 = 30
- Positive tests among no cancer group: 960 $\times$ 0.07 = 67.2
- Total positive tests: 30 + 67.2 = 97.2

Ratio of true positives to total positives: $\frac{30}{97.3} = 0.309$

How would you counsel a family member who had a positive test?

> The probability of cancer given that a single test is positive is only ~30%. So get retested. The probability of two false positives is lower than of one.

How do your results change when one of the values changes? Calculate each of the following separately. If you haven't already done so, you may wish to return to the code you wrote above and assign variables that you can change:

1. Only 1% of men over 65 have prostate cancer, but the other values are the same as above
2. The true positive rate for the PSA test is 95%, but the other values are the same as above
3. The false positive rate is 1%, but the other values are the same as above

```{r}
##FIXME

# 1
Ca_rate <- 0.01
True_pos <- 0.75
False_pos <- 0.07
(True_pos * Ca_rate) / (True_pos * Ca_rate + (1 - Ca_rate) * False_pos)

# 2
Ca_rate <- 0.04
True_pos <- 0.95
False_pos <- 0.07
(True_pos * Ca_rate) / (True_pos * Ca_rate + (1 - Ca_rate) * False_pos)

# 3
Ca_rate <- 0.04
True_pos <- 0.75
False_pos <- 0.01
(True_pos * Ca_rate) / (True_pos * Ca_rate + (1 - Ca_rate) * False_pos)
```

What is your interpretation of the factors that result in the condition, given a single positive test?

> Each has a role and they interact with each other. If the rate is low, then the probability of a false positive is pretty high (#1 shows about 90%). But holding the other two constant and raising the rate of true positive tests only increases the probability from 30% to 36%. Lowering the false positive rate has a huge effect, wherein the probability goes from 30% to 76%.


## Random Samples

R has a random number generator (actually a [pseudorandom number generator](https://en.wikipedia.org/wiki/Pseudorandom_number_generator)). Being able to simulate randomness is a critical component of programming. However, how does one avoid getting slightly different results every time you run your program if it includes randomness? R's solution, and the way to make your code reproducible, is to set the seed using `set.seed()`. Imagine you run a power simulation by randomly generating data and claim your power is 84%. How would another research confirm your results? Let's explore this feature.

### Activity

Without setting the seed, generate two objects named AA and BB consisting of 5 numbers drawn from a normal distribution with a mean of 0 and a standard deviation of 1 using `rnorm()` and print AA and BB. Run this chunk more than once. Do you get the same answer each time?

```{r}
# FIXME
AA <- rnorm(5)
BB <- rnorm(5)
tibble(AA, BB)

AA <- rnorm(5)
BB <- rnorm(5)
tibble(AA, BB)
```

> No. You get different answers each time.

Now, set the seed for the random number generator, and do the same as above. Chose any integer and place it in `set.seed()`. Run this chunk more than once. Do you get the same answer each time? Are AA and BB the same?

```{r}
# FIXME
set.seed(34288)
AA <- rnorm(5)
BB <- rnorm(5)
tibble(AA, BB)

set.seed(34288)
AA <- rnorm(5)
BB <- rnorm(5)
tibble(AA, BB)
```

> Yes. Now the sets are the same, but AA and BB are different.

What would happen if you set the seed, generate AA, set the seed again with the same number and then generate BB? Try this.

```{r}
# FIXME
set.seed(34288)
AA <- rnorm(5)
set.seed(34288)
BB <- rnorm(5)
tibble(AA, BB)
```

> AA and BB are now equal.

One key feature for simulating randomness in R is the `sample()` function. Imagine you had a list of potential participants for a study (e.g., the list of likely voters in the U.S.). You could use `sample()` to choose a random set. Let's try this with a set of letters representing people and we will randomly assign each to a group by sampling `c('Treatment','Control')` *with replacement*.

Look at the help file for `sample()` and see what the arguments below mean.

```{r}
set.seed(592777)
pp_all <- tibble(id = letters[1:26],
                 sex = sample(c('Treatment', 'Control'), 26, replace = TRUE))
```

Try the following:

1. Generate a random sample of 5 elements from the `id` column without replacement
2. Select a random sample of 5 ids with their associated sex (hint: sample the set of row indices [1 to 26] and take only those rows). Look at the help for the tidyverse function`slice_sample()` and see if you can figure out how to sclice a random set of rows using a pipe.

```{r}
# FIXME
# 1
sample(pp_all$id, 5)

# 2
pp_all[sample(seq(1, nrow(pp_all)), 5), ]
pp_all %>% 
  slice_sample(n = 5)
```

How would you use `slice_sample()` to randomly select 50% of the rows without first counting the number of rows?

```{r}
## FIXME
pp_all %>% 
  slice_sample(prop = 0.5)
```

One final note on `set.seed()`: typically, you just need to set the seed once at the top of your script to anchor the random number generator. However, any time you generate random numbers or sample, you should consider whether you need to set the seed.


## Distributions

We want to give you some practice generating random numbers and plotting. These activities are critical to numerical simulation, which we will do off and on throughout the course.

### Activity

For each of the following, generate a set of values and plot a histogram. You may want to adjust the number of bins (`bins = ` argument to `geom_histogram()`).

1. 5 values from a normal distribution with a mean of 5 and a standard deviation of 1
2. 100 values from a normal distribution with a mean of 5 and a standard deviation of 1
3. 100000 values from a normal distribution with a mean of 5 and a standard deviation of 1
4. 5 values from a normal distribution with a mean of 5 and a standard deviation of 5
5. 100 values from a normal distribution with a mean of 5 and a standard deviation of 5
6. 100000 values from a normal distribution with a mean of 5 and a standard deviation of 5
7. 1000 values from a uniform distribution with a minimum of 0 and maximum of 100.

```{r}
#FIXME
set.seed(42878979)

# 1
ggplot(tibble(num = rnorm(5, 5, 1)), aes(num)) +
  geom_histogram(bins = 4)

# 2
ggplot(tibble(num = rnorm(100, 5, 1)), aes(num)) +
  geom_histogram(bins = 30)

# 3
xx3 <- tibble(num = rnorm(100000, 5, 1))
ggplot(xx3, aes(num)) +
  geom_histogram(bins = 50)

# 4
ggplot(tibble(num = rnorm(5, 5, 5)), aes(num)) +
  geom_histogram(bins = 4)

# 5
ggplot(tibble(num = rnorm(100, 5, 5)), aes(num)) +
  geom_histogram(bins = 30)

# 6
xx6 <- tibble(num = rnorm(100000, 5, 5))
ggplot(xx6, aes(num)) +
  geom_histogram(bins = 50)

# 7
ggplot(tibble(num = runif(1000, 0, 100)), aes(num)) +
  geom_histogram(bins = 30)

```

Create a density plot for #3 and #6 above on the same plot. First create a single data frame with both sets and a column identifying each group.

```{r}
#FIXME
n <- 100000
xx.b <- tibble(id = rep(c('a', 'b'), each = n),
               value = c(rnorm(n, 5, 1), rnorm(n, 5, 5)))

ggplot(xx.b, aes(x = value, color = id)) +
  geom_density()

# or

ggplot(xx.b, aes(x = value, color = id, fill = id)) +
  geom_density(alpha = 1/5)
```

Add a vertical line to your plot at x = 7.

```{r}
#FIXME
ggplot(xx.b, aes(x = value, color = id, fill = id)) +
  geom_vline(xintercept = 7) +
  geom_density(alpha = 1/5)
```

Consider #3 and #6 from above. What proportion of values from each set are above 7?

```{r}
# FIXME
xx.b %>%
  group_by(id) %>%
  summarize(pct = sum(value > 7) / n)

#3
nrow(xx3[xx3$num > 7, ]) / nrow(xx3)

#6
nrow(xx6[xx6$num > 7, ]) / nrow(xx6)
```

The following code uses `pnorm()` to calculate the probability of observing a value of 7 or greater for each distribution.

```{r}
pnorm(7, mean = 5, sd = 1, lower.tail = FALSE)
pnorm(7, mean = 5, sd = 5, lower.tail = FALSE)
```

Compare the values returned by `pnorm()` to those you calculated manually above:

> They are nearly identical.

Although `pnorm()` (and the other `p` functions) use equations to calculate probabilities, as n gets very large, the values will asymptotically approach simply summing up observations above or below some critical value.
