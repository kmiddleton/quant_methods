---
title: 'Problem Set 12'
author: "Your Name Here: Group X"
date: 'Last updated: `r Sys.Date()`'
output:
  html_document:
    smart: no
    theme: flatly
    toc: true
    toc_float: true
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(cowplot)

theme_set(theme_cowplot())

# This option turn on caching of chunks. This will dramatically
# speed up knitting, because only chunks that have changed will
# be recompiled.
knitr::opts_chunk$set(cache = TRUE)
```

<!--
Datasets
  Sole.xlsx
  Stalkies.csv
  Heart_Transplants.xlsx
-->

## Return of the Sole

In lecture, we looked at presence/absence data for the common sole ([*Solea solea*](https://en.wikipedia.org/wiki/Common_sole)) predicted by different factors such as the salinity of the water. Here we will focus on the composition of the substrate.  

### Activity

Load the sole data from the file `Sole.xlsx`. Several of the variables are categorical and should be converted into factors: season, month, area, and Solea_solea. Go ahead and do this now. As a final step, convert your object with the data into a `data.frame` with `as.data.frame()`.

```{r}
# FIXME
M <- read_excel("../data/Sole.xlsx")
M <- M %>% mutate(season = factor(season),
                  month = factor(month),
                  area = factor(area),
                  Solea_solea = factor(Solea_solea))
M <- M %>% as.data.frame()
str(M)
```

The columns `gravel`, `large_sand`, `med_fine_sand`, and `mud` represent their proportional concentrations in the substrate (they sum to 100). Calculate a composite score for "substrate". Use principal components analysis on these columns.

```{r}
# FIXME
z <- prcomp(~ gravel + large_sand + med_fine_sand + mud,
              data = M,
              scale. = TRUE,
              center = TRUE)
```

Use the `summary()` and `print()` methods to determine the percent of variance accounted for by each PC and the relative loadings of each variable.

```{r}
# FIXME
summary(z)
print(z)
```

What is your interpretation of the PCA?

> PC 1 accounts for 62% of the variation, which is fairly high. Mud loads positively, whereas two kinds of sand load negatively. Gravel doesn't load at all really. So PC represents a mud vs. sand axis.

Fit a logistic regression where presence of sole is predicted by the first PC from the PCA above. Refer to the lecture slides if you need to.

```{r}
# FIXME
fm2 <- glm(Solea_solea ~ z$x[, 1], data = M, family = "binomial")
```

Try to interpret the output of the summary of the fitted model. What kind of substrate do sole appear to prefer?

```{r}
# FIXME
summary(fm2)
```

> PC is basically as axis of sand with values in negative PC1 scores to mud in positive PC1 scores. Gravel doesn't load appreciably on PC1. Logistic regression shows that as PC1 score increases, sole are less likely to be present (negative coefficient estimate). So sole are less likely to be present as the substrate gets more muddy. They are more likely to be present as the substrate gets more sandy.

The code below plots the outcome. Change eval=FALSE to eval=TRUE to run this chunk when knitting.

```{r, eval=FALSE}
# Plotting the outcome.
# FIXME
M$PC1 <- z$x[, 1]

ggplot(M, aes(x = PC1,
              y = as.numeric(Solea_solea) - 1)) +
  geom_hline(yintercept = 0.5, linetype = "dotted", size = 0.5) +
  geom_smooth(method = "glm",
              formula = y ~ x,
              method.args = list(family = "binomial"),
              se = FALSE, size = 2) +
  geom_point(size = 3) +
  labs(y = "Probability of Presence", x = "PC1") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +
  annotate("text", x = -3, y = -0.2, label = "Sandy") +
  annotate("text", x = 3, y = -0.2, label = "Muddy")
```


## Randomization and Empirical P-values

Randomization is an approach hypothesis testing that doesn't rely on the same set of assumption as the "original" test. The general procedure is:

1. Fit the model to the observed data.
2. Decide on a test statistic to use for the randomization (mean, difference of means, *t*, *F*, etc.).
3. Perform the randomization:
    - Calculate the test statistic for the *observed* data
    - Randomly shuffle the observations
    - Calculate the test statistic for that group
    - Repeat thousands of times
4. Plot a histogram of the resulting set of test statistics and add a line denoting your observed value
5. Determine the proportion of random combinations resulting in a test statistic more extreme than the observed value ("empirical *P*")

Remember to start with a small number of iterations (10 or 100) until you get the code working correctly. Then increase to 10,000 for a final analysis.


### Worked example: Stalk-eyed flies

We will start with a worked example: compare the mean eye span in stalk-eyed flies raised on two food sources. This model is a good candidate for randomization because the variances are unequal (there is about 4x difference).

Study the code below, and make sure that you understand what each line does.

```{r, flies1, message=FALSE}
# Use the tictoc package to time how long the code takes.
library(tictoc)

# Read data
stalk <- read_csv("../data/Stalkies.csv", col_types = "cd")

# Check standard deviations
stalk %>% 
  group_by(food_source) %>% 
  summarize(st_dev = sd(eye_span),
            .groups = "drop")

# Some thoughtful plotting
ggplot(stalk, aes(x = food_source, y = eye_span)) +
  geom_point(position = position_jitter(width = 0.05), alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", size = 3, color = "red") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.1,
               color = "red", size = 0.7) +
  labs(x = "Food Source", y = "Eye Span")

set.seed(8987324)
nreps <- 1e5
t_stats <- numeric(nreps)
t_stats[1] <- t.test(eye_span ~ food_source, data = stalk)$statistic

tic() # Start timer
for (ii in 2:nreps) {
  t_stats[ii] <- t.test(sample(eye_span) ~ food_source, data = stalk)$statistic
}
toc() # Stop timer

tibble(t_stats) %>%
  ggplot(aes(t_stats)) +
  geom_histogram(bins = 30) +
  geom_vline(xintercept = t_stats[1], color = "red") +
  labs(x = "t statistics", y = "Count")

2 * mean(t_stats >= t_stats[1])

t.test(eye_span ~ food_source, data = stalk)
```

10^5^ iterations took ~60 seconds on a single processor. We don't need to run that many iterations to get a good sense that the empirical P-value is going to be very low. The analytical *P* is 6e-10, so we expect the empirical *P* to be on the same scale.

We can use parallel processing to speed things up considerably, taking advantage of the fact that we are really just doing the same kind of calculation over and over.

The code below implements a simple parallel loop using some straightforward R packages. Some of this code will look unfamiliar, but we have commented it for you, in case you want to try something like this with your own data. Basically we set things up as we normally do, setting up an empty vector to hold the output and assign the observed value to the first position. But rather than doing a for loop, we will use the furrr package (https://furrr.futureverse.org/), which handle the parallelization and collection of the results.

The following chunk will not run during knitting.

```{r, flies2, eval=FALSE}
# Load packages
library(furrr)

# Calculate observed t-statistic
t_obs <- t.test(eye_span ~ food_source, data = stalk)$statistic

# Set up iterations
nreps <- 1e5 - 1

# Set up parallel processor
# Use the number of cores minus one to reserve some processing power for
# system processes.
n_cores <- availableCores() - 1
message("Using ", n_cores, " cores.")

# Setup parallelization
plan(multisession, workers = n_cores)

# Function to do the randomized t-test and return the t-statistic only.
t_rand <- function(.x, stalk) { # the 1st parameter is the iterator .x
  rnd_t <- t.test(sample(eye_span) ~ food_source, data = stalk)
  return(as.numeric(rnd_t$statistic))
}

# Parallel randomization execute t_rand(), and combine the output into
# t_stats (numeric vector).
tic()
rand_ts <- future_map_dbl(.x = 1:nreps,
               .f = t_rand,
               stalk = stalk,
               .options = furrr_options(seed = TRUE))
toc()

# Stop cluster
plan(sequential)

# Combine observed and randomized
t_stats <- c(t_obs, rand_ts)

2 * mean(t_stats >= t_stats[1])
```

The same number of iterations but using 7 processors takes 16.9 seconds.

```{r}
# Iterations per second, 1 processor
(p1 <- 60.6 / nreps)

# Iterations per second, 7 processors
(p7 <- 16.9 / nreps)

p1 / p7
```

We get a speed-up of about 3.6 times. There is some overhead in the parallelization, passing data back and forth between the processes, so we don't get 7x the speed that we might expect.


### Heart Transplant Survivorship (PS 08)

For the data on survivorship after heart transplant, we had to transform the data due to unequal variances. That is not necessary when we use randomization. Reanalyze these data without transformation, testing the same hypothesis as before.

Refer to the key for PS 08 to refresh yourself with the question and adapt the code from the example above (either sequential or parallel). Otherwise we will leave this exercise undirected.

```{r, heart_transplants}
# FIXME
M <- read_excel("../data/Heart_Transplants.xlsx") %>%
  mutate(Mismatch_Degree = fct_inorder(Mismatch_Degree))

ggplot(M, aes(x = Mismatch_Degree, y = Survival_Days)) +
  geom_point(position = position_jitter(width = 0.05), alpha = 0.5) +
  stat_summary(fun.y = mean, geom = "point", size = 3, color = "red") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.1,
               color = "red", size = 0.7) +
  labs(x = "Mismatch Degree", y = "Survival (days)")

fm <- lm(Survival_Days ~ Mismatch_Degree, data = M)
obs <- summary(fm)

set.seed(823476)
nreps <- 1e4
F_stats <- numeric(nreps)
F_stats[1] <- obs$fstatistic["value"]

for (ii in 2:nreps) {
  fm_rand <- lm(sample(Survival_Days) ~ Mismatch_Degree,
                    data = M)
  F_stats[ii] <- summary(fm_rand)$fstatistic["value"]
}

tibble(F_stats) %>%
  ggplot(aes(F_stats)) +
  geom_histogram(bins = 30) +
  geom_vline(xintercept = F_stats[1], color = "red") +
  labs(x = "F statistics", y = "Count")

mean(F_stats >= F_stats[1])
```

