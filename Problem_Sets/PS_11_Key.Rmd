---
title: 'Problem Set 11'
author: "Your Name Here: Group X"
date: 'Last updated: `r Sys.Date()`'
output:
  html_document:
    smart: no
    theme: flatly
    toc: true
    toc_float: true
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
library(cowplot)
library(ICC)
library(pwr)

theme_set(theme_cowplot())
```


## Repeatability: Intraclass correlation coefficient

The model you use to calculate the intraclass correlation coefficient *is* a multilevel model. You have repeated measurements for a single specimen. Those measurements are obviously not independent from one another (that is the point of repeated measurements -- to estimate the consistency of measurements as compared to the differences between individuals). The major question you want to ask is: What is the relative between *measurement* vs. between *specimen* variation?

We will fit this model in two ways: using `aov()` and using the `ICC` package. 

The data we will be working with includes repeated measurements of the femur of Walking Sticks:

<div style="width:350px">
![](https://i.imgur.com/CVTtMkJ.png)
</div>

Because the measurements are small (~ 0.25 cm), you are concerned that they will not be very repeatable. Before collecting all the data, you want to estimate the intraclass correlation coefficient of these measurements.

You take 2 measurements each on 25 different walking stick femurs, which are included in the files `WalkingStickFemurs.csv`.

### Activity

Load the data in `WalkingStickFemurs.csv`. Convert `Specimen` to a factor so that R will treat it as categorical rather than as numeric.

```{r echo=FALSE}
# FIXME
M <- read_csv("../data/WalkingStickFemurs.csv", col_types = "ddd") |> 
  mutate(Specimen = factor(Specimen))
```

Look at the structure of the data. The data are in long format, with one measurement per row. We want to be able to plot Measurement 1 vs. Measurement 2 to visualize the paired relationship. To do so, we need to convert the data into wide format, with 2 columns per Specimen: Measurement 1 and Measurement 2.

Pivot the data to wide:

- Use `Specimen` is the ID
- Take values from `Femur_length`
- Take column names from `Measurement`
- Use the `names_prefix =` option to prefix "Measurement_" before the column name

```{r}
# FIXME
glimpse(M)

M_wide <- M |> 
  pivot_wider(id_cols = Specimen, names_from = Measurement,
              values_from = Femur_length, names_prefix = "Measurement_")
```

Plot the pairs of observations as a scatterplot.

- Add a line with a slope of 1 and intercept of 0 using `geom_abline()`
- Set the axis coordinates to equal scaling with `coord_equal()`

```{r}
# FIXME
ggplot(M_wide, aes(Measurement_1, Measurement_2)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  coord_equal()
```

Based on your plot, do you expect repeatability to be high or low? Give an estimate?

> The points are fairly close to the line, so repeatability should be ok.

Follow the example from lecture to calculate repeatability of the femur length  measurement using `aov()`. As in the lecture, you can just manually copy the values from the `aov()` summary rather than trying to extract them programmatically.

```{r}
# FIXME
fm <- summary(aov(Femur_length ~ Specimen, data = M))

var_a <- (0.002464 - 0.000356) / 2
var_a / (var_a + 0.000356)
```

What value of repeatability to you find?

> ~0.75

Calculate repeatability of the femur length (`Femur_length`) measurement using `ICCest()` from the `ICC` package (you might need to install the package).

```{r}
# FIXME
ICCest(x = M$Specimen, y = M$Femur_length)
```

Compare the results

> The numbers are very similar. This is probably just due to rounding error introduced by manually copying the values from the first model. Overally, the measurements are pretty repeatable.

Would you be comfortable going forward with data collection given this value for ICC?

> Maybe or maybe not. If we expect fairly large differences between groups, then it's probably fine. But if the differences are small, then there may be so much variation associated with taking measurements that it will swamp out the variation between groups. It's probably fine.


## Planning experiments

Consider that you are planning some experiments, use the `pwr` package to calculate the unknown quantity for each of the following situations. Assume that $\alpha$ = 0.05 for all tests.

### Activity

Use `cohen.ES()` to look up the effect size for a "small" effect for a *t*-test.

```{r}
# FIXME
cohen.ES(test = "t", size = "small")
```

Calculate the sample size (*n*) needed in each group of a two-sample *t*-test with power = 0.80 to detect a small effect (use the effect size from above).

```{r}
# FIXME
pwr.t.test(d = 0.2, power = 0.80, type = "two.sample")
```

Repeat the test above but for a paired *t*-test.

```{r}
# FIXME
pwr.t.test(d = 0.2, power = 0.80, type = "paired")
```

Calculate the number of observations for a correlation test where you estimate a correlation coefficient of 0.6. Power should be 0.80.

```{r}
# FIXME
pwr.r.test(r = 0.6, power = 0.8)
```

Calculate the power for a correlation test where you estimate the correlation coefficient to be 0.4, for a sample size of 15.

```{r}
# FIXME
pwr.r.test(r = 0.4, n = 15)
```


## RNAseq (gene expression) on males and females of the Glanville Fritillary

```{r}
## FIXME
# Data preparation
set.seed(28462)

quant.norm <- function(y) {
  nn <- qqnorm(y, plot.it = FALSE)
  return(nn$x)
}

sid <- read_csv("../data/Butteryfly_IDs.csv",
                col_names = c("ID", "Treatment", "Sex", "Population"))
sid <- sid |>
  mutate(Treatment = str_replace(Treatment, "treatment: ", ""),
         Sex = str_replace(Sex, "Sex: ", ""),
         Population = str_replace(Population, "population: ", ""),
         ID2 = str_split(ID, "_", simplify = TRUE)[, 2],
         ID = str_split(ID, "_", simplify = TRUE)[, 1],
         ID = str_replace_all(ID, "-", "_")) |>
  filter(ID2 == 450) |>
  dplyr::select(-ID2)

gg <- read_delim("../data/Butterfly_NormalizedCountsGenes.txt",
                 delim = "\t")
samp.names <- colnames(gg)[-1]
gene.names <- gg$gene
gg <- t(gg[, -1])
rr.temp <- row.names(gg)
gg <- apply(gg, 2, function(x) quant.norm(x))
colnames(gg) <- gene.names
rownames(gg) <- rr.temp
gg <- bind_cols(
  tibble(ID = str_replace_all(row.names(gg), "-", "_")),
  as.data.frame(gg))

ngenes <- 100
gg_samp <- gg[, c(1, sample(size = ngenes, x = 2:ncol(gg)))]

M <- left_join(sid, gg_samp)
M <- M[,-c(2,4)]

write_csv(M, file = "../data/Butterfly_Gene_Expression.csv")
```

Glanville Fritillary butterflies are a model organism for studying dispersal and metapopulation dynamics, because they live in isolated meadows.

<div style="width:350px">
![](https://imgur.com/d8mwElE.jpg)
</div>

### Activities

Here, we load in the Butterfly Gene Expression data (`Butterfly_Gene_Expression.csv`). This is a `tibble` of sample id, sex, and 100 normalized gene expression measures (this is trimmed down from an original over 8,000 expression measures). We will perform 100 regressions using `lm()`, predicting each gene expression measure from the sex variable. The `lm()` function can fit multiple Y's at once. See the code below to see how this works for this dataset.

Note this method produces a list of `lm()` results. We have written a function (`getP()` see above) to extract the relevant P-value from a list of this type. We will do this for this set of models and assign the p-values to an object, `obsP`. 

Change `eval = FALSE` to `eval = TRUE` and run the chunk below. You might need to change the path to `Butterfly_Gene_Expression.csv`.

```{r eval=TRUE}
getP <- function(fm) {
  sum.set <- summary(fm)
  p.set <- lapply(sum.set, function(x) x[['coefficients']][2, 4])
  return(unlist(p.set))
}

M <- read_csv("../data/Butterfly_Gene_Expression.csv")
Ys <- as.matrix(M[, 3:ncol(M)])
fm <- lm(Ys ~ Sex, data = M)

obsP <- tibble('P' = getP(fm))
```

Visualize your *P*-values by plotting a histogram and a q-q plot. For the q-q plot, transform your *P*-values to -log10(*P*-values) and sort them from smallest to largest. Then, generate expected values from the uniform distribution using `runif()` and again transform and sort them. Now plot observed versus expected values and add a 1:1 line (intercept = 0, slope = 1).

```{r}
set.seed(273645)

ggplot(obsP, aes(P)) +
  geom_histogram(bins = 20)

qqP <- tibble('observed' = sort(-log10(obsP$P)),
              'expected' = sort(-log10(runif(length(obsP$P), 0, 1))))

ggplot(qqP, aes(x = expected, y = observed)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1)

```

Based on these visualizations, do you think there are true positives in this data set?

> Probably. The P-values deviate pretty strongly from the expected line.

Use R's built-in `p.adjust()` function to adjust the P-values using the sequential Bonferroni correction (Holm procedure). You don't have to sort the P-values first, but it can make it easier to pick out ones that remain significant. Print a `tibble` with the observed P-value and sequential Bonferroni corrected P-value. Finally, count the number of P-values that are less than 0.05.

```{r}
# FIXME
seq_bonf <- p.adjust(obsP$P, method = "holm")
tibble(P = obsP$P,
       seq_bonf) |>
  arrange(P) |>
  filter(seq_bonf <= 0.05)
sum(seq_bonf < 0.05)
```

Repeat the procedure above, but now use the false discovery rate procedure of Benjamini and Hochberg.

```{r}
# FIXME
fdr <- p.adjust(obsP$P, method = "fdr")
tibble(P = obsP$P,
       fdr) |>
  arrange(P) |>
  filter(fdr <= 0.05)
sum(fdr < 0.05)
```

Follow the code in lecture to carry out a pFDR analysis of these *P*-values. You will probably need to install the `qvalue` package, which is available through Bioconductor (rather than CRAN). https://www.bioconductor.org/packages/release/bioc/html/qvalue.html

**Note**: When you install from bioconductor, it will ask you if you want to update your packages, expecting a response at the command line. You can enter "y" or "n", but you need to enter something. Otherwise, R will appear to be frozen.

```{r}
library(qvalue)
qobj <- qvalue(obsP$P, fdr.level = 0.05, pi0.method = "smoother")
summary(qobj)
```

What is the value of $\pi_0$? What does this value represent?

> 0.39. This means that only 39% of the null hypotheses are true.

How many P-values are associated with q-values less than 0.05?

> 29 (of 32 nominally less than 0.05)

What is an adjusted $\alpha$-level that will control pDFR at 0.05?

```{r}
max(qobj$pvalues[qobj$qvalues <= 0.05])
```

The code below shows a randomization that we can use to estimate the number of expected false positives for this experiment. 1) We want to keep the correlation structure of the gene expression measures. An easy way to do this is to shuffle the sex labels and leave the expression measures the same. 2) We performed our set of 100 tests in the same way that we did above. 3) We collected the associated p values using the `getP` function. 4) These were put into a 1000 x 100 matrix with each column as one iteration. 

```{r randomization, cache=TRUE, eval=FALSE}

set.seed(874628)
niter <- 1000

Ys <- as.matrix(M[, 3:ncol(M)])
Sex <- M$Sex

allP <- matrix(NA, ncol(Ys), niter)

for (kk in 1:niter) {
  fms <- lm(Ys ~ sample(Sex))
  allP[, kk] <- getP(fms)
}

# Change path to where you want to save the file
saveRDS(allP, file="../data/Shuffle_Expression.rds")

```

Load this matrix we generated using the `readRDS` function (this is a new one for you that will read an R object in directly) and assign it to an object called `allP`.

```{r}
# FIXME
allP <- readRDS(file="../data/Shuffle_Expression.rds")
```

Visualize the P-values from one or a few of these iterations as you did above with a histogram and a q-q plot.

```{r}
# FIXME
it1 <- tibble('P' = allP[, 5])
ggplot(it1, aes(P)) +
  geom_histogram(bins = 20)

qqP <- tibble('observed' = sort(-log10(it1$P)),
              'expected' = sort(-log10(runif(100, 0, 1))))

ggplot(qqP, aes(x = expected, y = observed)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1)
```

For each iteration, get a count of the number of positives at a threshold of 0.05. Visualize the number of positives with a histogram. Keep in mind, because you have randomized the data, *all positives here are false positives*.

- Calculate the average number of false positives and the average false positive rate at a threshold of 0.05.
- Now calculate the Family-Wise Error Rate (FWER) at a threshold of 0.05 by calculating the proportion of iterations that result in at least one significant result.
- Use your average estimated number of false positives to calculate the false discovery rate at a threshold of 0.05. Note you will need to consider your observed number of positives for this calculation.


```{r}
# FIXME
th <- 0.05

pos.counts <- tibble(
  'counts' = apply(allP, 2, function(x) sum(x < th)))

ggplot(pos.counts, aes(counts)) +
  geom_histogram(bins = 20)

mean(pos.counts$counts)

mean(pos.counts$counts) / 100

sum(pos.counts >= 1) / 1000

mean(pos.counts$counts) / sum(obsP$P < th)
```

Now use this same procedure to calculate the false positive rate, FWER, and false discovery rate at the range of thresholds given below. Store your output (including the threshold) in a `tibble`.

```{r}
# FIXME
thresholds <- seq(0.0005, 0.05 , length = 200)

#FIXME
output <- tibble('threshold' = thresholds,
                 'FP' = numeric(length(thresholds)),
                 'FWER' = numeric(length(thresholds)),
                 'FDR' = numeric(length(thresholds)))

for (tt in 1:length(thresholds)) {
  th <- thresholds[tt]
  pos.counts <- tibble(
    'counts' = apply(allP, 2, function(x) sum(x < th)))
  output[tt,'FP'] <- mean(pos.counts$counts) / 100
  output[tt,'FWER'] <- sum(pos.counts >= 1) / 1000
  output[tt,'FDR'] <- mean(pos.counts$counts) / sum(obsP$P < th)
}

output
max(output$threshold[output$FDR <= 0.05])
```

Make plots of the FDR, FP, and FWER plotted against the threshold (feel free to make three separate plots). In each, draw a horizontal line at 5%.

```{r}
#FIXME
output |>
  ggplot(aes(threshold, FDR)) +
  geom_point() +
  geom_hline(yintercept = 0.05)

output |>
  ggplot(aes(threshold, FP)) +
  geom_point() +
  geom_hline(yintercept = 0.05)

output |>
  ggplot(aes(threshold, FWER)) +
  geom_point() +
  geom_hline(yintercept = 0.05)
```

Inspecting the data you made above, what P-value threshold should you use if you want a false discovery rate of 5%?

> It looks like a threshold around 0.008 would give an FDR of 0.05. 

Calculate the FWER corresponding to an alpha of 5% by calculating the lowest P-value for each iteration. Then, use the `quantile()` function to calculate the 5% quantile. hint: you will want to use `apply()` here.

```{r}
minP <- apply(allP, 2, min)
quantile(minP, 0.05)
```
