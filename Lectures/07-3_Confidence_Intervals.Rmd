---
title: "Intervals"
subtitle: "Quantitative Methods in Life Sciences"
author: 'Elizabeth King, Kevin Middleton, and Lauren Sullivan'
output:
  ioslides_presentation:
    fig_width: 8
    css: styles.css
csl: evolution.csl
bibliography: Multivariate.bib
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(cowplot)
library(rethinking)
theme_set(theme_cowplot())
source("https://raw.githubusercontent.com/kmiddleton/quant_methods/master/Lectures/Shade_Distributions.R")
```


## Intervals measure uncertainty in a parameter estimate

- Analytical Confidence Intervals  
    - Approximate calculation relying on $\pm 2 \times SEM$ 
    - Exact calculate using a critical *t*-value and appropriate degrees of freedom
- Maximum Likelihood Confidence Intervals
    - Iterate over possible parameter values 
    - Identify the range of parameter values associated with likelihoods around the maximum likelihood estimate
- Bayesian Credible Intervals
    - Region including highest desired percentage of posterior density


## Calculating exact confidence intervals

<div class="columns-2">

```{r, echo=FALSE, fig.width = 4}
shade_normal(0.025)
```

- $2$ in $\pm 2 \times SEM$ is an approximation
- True value is ~1.96 for a standard normal distribution (assuming infinite sample size)
- Exact confidence intervals rely on the *t*-distribution
- Increase width of CI for smaller sample size

</center>

## Calculating exact confidence intervals

```{r echo=FALSE}
shade_t(0.025, 5) +
  ggtitle(TeX("$t$-distribution with df = 5"))
```

Need the critical value that marks the 2.5% cutoff at each tail.

## Calculating exact confidence intervals

Multiply the $SEM$ by the *t*-value encompassing 95% for a *t* distribution with a given degrees of freedom (e.g., $n-1$).

```{r t_plot, message=FALSE, fig.height=3.5, echo=FALSE, warning=FALSE}
x <- seq(-2.5, 2.5, by = 0.01)

sim <- tibble(df = c(2, 5, 20)) %>%
  group_by(df) %>%
  do(tibble(x = x, y = dt(x, .$df))) %>%
  mutate(Parameters = paste0("df = ", df)) %>%
  ungroup() %>%
  mutate(Parameters = factor(Parameters, levels = unique(Parameters)))

norm <- tibble(
  x = x,
  y = dnorm(x, 0, 1)
)

pal <- palette()[2:4]

ggplot() +
  geom_line(data = norm, aes(x, y), size = 3) +
  geom_line(data = sim, aes(x, y, color = Parameters), size = 1.5) +
  scale_color_manual(values = pal, name = "Degrees of\nFreedom") +
  labs(x = "t", y = "Relative Likelihood") +
  theme(legend.position = c(0.85, 0.75))
```


## Calculating exact confidence intervals

```{r}
qt(0.975, 10 - 1)

qt(0.975, 100 - 1)

qt(0.975, 1000000000 - 1)

qnorm(0.975, 0, 1)
```


## The `r`, `d`, `p`, and `q` functions for distributions

Example for a normal distribution (Specify `mean` and `sd` or defaults is standard normal: $\mu = 0$, $\sigma = 1$):

1. `rnorm(n, ...)`: `n` random draws
1. `dnorm(x, ...)`: Relative likelihood (density) at `x` values
1. `pnorm(q, ...)`: (Lower) tail probability for a quantile `q` 
1. `qnorm(p, ...)`: Quantile for a given (lower) tail probability `p`

- `lower.tail = FALSE` for the upper tail
- `log = TRUE` for log-probability


## 95% CI for snake undulation (*n* = 8)

```{r}
undulation_rate <- c(0.9, 1.2, 1.2, 1.3, 1.4, 1.4, 1.6, 2.0)
undulation_mean <- mean(undulation_rate)
(undulation_SEM <- sd(undulation_rate) / sqrt(length(undulation_rate)))
(crit <- qt(0.025, df = 8 - 1, lower.tail = FALSE))
lower <- undulation_mean - crit * undulation_SEM
upper <- undulation_mean + crit * undulation_SEM
c(lower, undulation_mean, upper)
```


## Bayesian Credible Intervals

- Summarize the posterior distributions of Bayesian analyses
- Range of the most plausible parameter estimates given the data and the model
- XX% highest density interval
- XX% quantile


## MCMC sampling

- Most general way to do Bayesian inference
- No complicated integrals
- Requires time and computational power


## MCMC sampling

```{r stan_sample, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE, results='hide'}
fm <- ulam(
  alist(
    undulation_rate ~ dnorm(mu, sigma),
    mu ~ cauchy(0, 3),
    sigma ~ exponential(1)
  ),
  data = list(undulation_rate = undulation_rate),
  iter = 1e4,
  chains = 4
)
```


## MCMC sampling output

```{r echo=FALSE}
rstan::traceplot(fm@stanfit, pars = c("mu", "sigma"))
```


## MCMC sampling

```{r echo=FALSE}
post <- as.data.frame(extract.samples(fm)) %>% 
  mutate(Sample = 1:length(mu))

post %>% 
  slice(1:20) %>% 
  gather(variable, value, -Sample) %>% 
  ggplot(aes(Sample, value)) +
  geom_line(alpha = 0.25) +
  geom_point(size = 2) +
  facet_grid(variable ~ ., scales = "free") +
  labs(y = "Estimate")
```


## MCMC method

- Current position (has a likelihood)
- Propose a change (has a likelihood)
- Move to proposed values with probability proportional to their ratio
- "Bad" jumps are possible with some non-zero probability


## Current estimates

Sample 1:

```{r}
post[1, ]
rel_liks <- dnorm(undulation_rate, mean = post$mu[1],
                  sd = post$sigma[1], log = TRUE)
(current_ll <- sum(rel_liks))
```


## Proposed estimates

```{r}
mu_prop <- 1.37
sigma_prop <- 0.3
rel_liks <- dnorm(undulation_rate, mean = mu_prop,
                  sd = sigma_prop, log = TRUE)
(proposed_ll <- sum(rel_liks))
```

```{r}
exp(proposed_ll) / exp(current_ll)
```

Ratio > 1, so definitely move.

```{r}
current_ll <- proposed_ll
```


## Proposed estimates

```{r}
proposed_ll <- sum(dnorm(undulation_rate,
                         mean = 1.5, sd = 0.22,
                         log = TRUE))
exp(proposed_ll) / exp(current_ll)
```

Ratio < 1, so the probability of moving is equal the ratio (here ~10%).

- This allows moves to lower likelihood estimates (as long as the probability of moving is not too small).


## MCMC sampling

The samples will oscillate around the most probable estimates, in proportion to their probabilities.

```{r echo=FALSE, fig.height = 4}
post <- as.data.frame(extract.samples(fm)) %>% 
  mutate(Sample = 1:length(mu))

post_long <- post %>% 
  slice(1:100) %>% 
  gather(variable, value, -Sample)

post_means <- post_long %>% 
  group_by(variable) %>% 
  summarize(param_mean = mean(value))

ggplot() +
  geom_line(data = post_long, aes(x = Sample, y = value), alpha = 0.25) +
  geom_point(data = post_long, aes(x = Sample, y = value), size = 2) +
  geom_hline(data = post_means,
             aes(yintercept = param_mean, color = variable),
             size = 2, alpha = 0.5) +
  scale_color_manual(values = c("darkblue", "darkred"), name = "Parameter") +
  facet_grid(variable ~ ., scales = "free") +
  labs(y = "Estimate")
```


## Bayesian credible intervals

Posterior distribution of mean undulation, given, the model (including priors) and data:

```{r, echo=FALSE}
p <- post %>% 
  select(mu) %>% 
  ggplot(aes(mu)) +
  geom_line(stat = "density") +
  labs(y = "Relative Likelihood")
p
```


## Bayesian credible intervals

95% Highest density interval is the most probable location for the mean (given the model and the data).

```{r echo=FALSE, fig.height=3.5}
(cred <- HPDI(post$mu, prob = 0.95))
p + 
  geom_vline(xintercept = cred, color = "coral", size = 1.5)
```


## Interpreting intervals

Frequentist interval: `r round(lower, 2)` -- `r round(upper, 2)`

- Future similar experiments and samples
- Does not indicate the probability of the parameter

Bayesian interval: `r round(cred[1], 2)` -- `r round(cred[2], 2)`

- These data and this model
- Relative probability within a region

