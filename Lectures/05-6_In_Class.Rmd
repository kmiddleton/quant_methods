---
title: "Unit 5 In Class Discussion"
subtitle: "Quantitative Methods in Life Sciences"
author: 'Elizabeth King, Kevin Middleton, and Lauren Sullivan'
output:
  ioslides_presentation:
    fig_width: 8
    css: styles.css
csl: evolution.csl
bibliography: Multivariate.bib
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
```


## Themes

- We have a plan. Trust us.
- Need practice coding, lectures not as good for learning coding
    - Several questions about loops
- Big picture of analytical vs. ML vs. resampling vs. Bayesian


## Progress Check 1

- Look at the key
- Questions next week


## Likelihood

> The log-likelihood is still unclear: does the log-likelihood lie between -Inf to +Inf? If that's the case, how do we understand how to use it to give an indication of the fit of the model?

> The most confusing lecture for me this week was Probability to Likelihood. If we could go over the dbinom() function and why we convert to log-likelihoods again that would be great. 

> similarly, a little more explanation for the glm and optim code in 5-4. (also random question, for those codes, why is x lowercase and y uppercase?)

> Can we have more examples on how to get the likelihood ratio using R?


## Analytical Frameworks

- What do we want you to understand about them?
- When to use each
- Does needing to use one imply bad design?
- More practical examples


## Frameworks

> Theoretically, I'm not quite grasping why someone would choose to use the different models. The analytical model feels like it makes pronouncements about data that exists and that the researcher currently has, while the other three make inferences about data that could be possible. To me, it seems like they are doing very different things between Analytical and the rest, while the remaining three do roughly the same thing, especially maximum likelihood and resampling.

> How do you determine which inference method to use in determining mean.


## Frameworks

> This may be a dumb question but what are models, are the named tests like t-tests, chi squared etc, considered to be models or are they something else? Or are these tests based on a model? 

> When using the maximum likelihood method, should we always use optimization? Or are there scenarios when grid approximation is preferred?


## Frameworks

> Could I use ML to validate the answer I got from using Bayesian method? Or will I get different answers depending on the size of the samples and other parameters?

> What type of framework have you found yourselves working in the most? Do people often specialize in certain frameworks? Recently, I have heard many people talk about knowing Bayesian as being a plus when it comes to getting a job, I'm not sure if that is related to the field or maybe the progression of statistical analysis in the age of data, or something else. What is your take on that?


## Bayesian inference

> Can you go over the stan function again and explain it?


## Priors

> When using prior knowledge for Bayesian method, how does one go about doing that? (is there an organized, systematic way of doing that)

