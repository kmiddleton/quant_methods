---
title: "Progress Check 1"
subtitle: "Quantitative Methods in Life Sciences"
author: 'Elizabeth King, Kevin Middleton and Lauren Sullivan'
output:
  ioslides_presentation:
    fig_width: 7
    css: styles.css
csl: evolution.csl
bibliography: Multivariate.bib
---

```{r setup, echo=FALSE, message=FALSE}
library(tidyverse)
library(cowplot)
theme_set(theme_cowplot())

library(palmerpenguins)
island_data <- tibble(
  island = as.character(levels(penguins$island)),
  latitude = c(-64.766667, -65.433333, -64.733333),
  longitude = c( -64.083333, -65.5, -64.233333)
)
```


## Topics for Today

1. Learning R: help, syntax, resources, time?
2. Distributions
3. Tidyverse functions
4. Data Visualization
5. Probability & Distributions


## Learning R {.smaller}

> I have the basics, but a lot of times the problem sets ask for more and it's a bit hard to understand even with outside help (internet, R help, etc.)

> ... (and this is a bit more philosophical) is there a "right" answer? Although you said at the beginning of the semester that there are many ways to do the same operation in R, it does seem like there are particular ways you would prefer us to do things in opposition to that. Could you be explicit about where we can have freedom to experiment and where you want "your" answer?


## Learning R {.smaller}

> I think I would most like a quick/comprehensive review of the 5 to 10 most used R functions for the class. It doesn't have to be long, but just an explanation of what they are, what they do, what their arguments are, how they work together, etc.

> Should we memorize these functions that we covered in class?


## Strategies for Learning R

1. Time. Practice. 
2. Using help files
    - ?unique
3. Tips
    - Make your own Help folder 
    - Develop a system for saving resources
    - Write pseudocode & use comments
    - Growth mindset
3. Extra Resources
    - For learning R & lots of other stuff (like Git)


## Distributions

> Does the sample size affect what type of distribution we use? How big should the population be in order to use a binomial distribution, for example? Is there a specific guide to help us pick the type of distribution for publication purposes? Can binomial data be normally distributed?

> I am confused about the Distribution part. The activity under the distribution section of Problem set 4 gave me a hard time; luckily, we work in groups so got help.


## What kind of data do I have?

Continuous values:

- Can the data take any value on the number line (including integers)?
- Normal (Gaussian) or some variation

Discrete "successes" with two possible outcomes:

- Yes/no, presence/absence, survived/didn't, A/a, XX/XY
- Binomial
- Poisson (counts per space/time)


## Distributions

> What are power analyses and are they actually useful, or just a way of trying to get your data to a point of potential 'normality'? Would you recommend using it for any type of analysis?

> I would like us to talk more on Normal distribution, specifically, on log normal distribution. When do we log transform data?


## Distributions

> The second question is related to distribution of data. Supposed we want to check which distribution our data fit in. Let's say we plot the histogram. Visually it looks that the data has a Poisson distribution with a lot of zero in our data. How can we test that it fits statistically that specific distribution?


## Tests of normality

```{r, echo=FALSE, fig.height=3}
x <- rnorm(5000)
ggplot(tibble(x), aes(x)) +
  geom_histogram(bins = 30)
```

```{r}
shapiro.test(x)
```


## Tests of normality

```{r, echo=FALSE, fig.height=3}
x <- runif(500)
ggplot(tibble(x), aes(x)) +
  geom_histogram(bins = 30)
```

```{r}
shapiro.test(x)
```


## Tests of normality

```{r, echo=FALSE, fig.height=3}
x <- rnorm(20)
ggplot(tibble(x), aes(x)) +
  geom_histogram(bins = 30)
```

```{r}
shapiro.test(x)
```


## Tibbles, matrices, and data.frames

> Dataframes, matrices, and tibbles are still a bit confusing. Could you go over the differences in each one and how they are similar and different?

> When is it appropriate to select creating a tibble over a data frame?

> What is the best way to determine if there are formatting issues in the data.

- `str()`, `glimpse()`, `unique()`, `count()`


## Slicing

> I still don't understand slice_sample() very well or how it works. Could you please go over it?

NYC Air quality May-September 1973

```{r}
str(airquality)
```


## Slicing specific rows

```{r}
airquality[c(1, 3, 5), ]
airquality |> slice(1, 3, 5)
```


## 7 rows

```{r}
airquality[sample(1:nrow(airquality), 7), ]

airquality |> slice_sample(n = 7)
```


## 5% of rows

```{r}
airquality[sample(1:nrow(airquality), nrow(airquality) %/% 20), ]

airquality |> slice_sample(prop = 0.05)
```


## Tidyverse: pivots

> Why is it good data practice to keep my data in a bunch of smaller tables that I join together?

> When making clean data, what is the best way to determine whether or not you need to make it longer or wider at a quick glance of the data.


## Pivots

Shape of your data:

- Wide: rows have multiple columns with values
- Long: rows have 1 column with values


## Wide data

Most common for data entry:

```{r}
library(palmerpenguins)
head(penguins)
```

Each row is a logical unit (e.g., sample, individual)


## Wide data

```{r}
island_data
```


## Long data

- Truly "tidy"
- Frequently impractical for data entry (lot of repeated values)
- Often useful for plotting
    - Column name becomes a value for a new variable
    - Cell value becomes the value for that new variable

`pivot_longer()`: wide $\rightarrow$ long

`pivot_wider()`: long $\rightarrow$ wide


## "Quoted" vs. unquoted variables

> When writing in R how do you know when to use " " and when not two when referring to variables and values.

- Most tidyverse functions can be unquoted
    - A few exceptions (e.g., `facet_wrap("variable")`)
- When you need a "string"
    - `names_to = "bill_measure"`
    - `today <- "Friday"`
- Mix in base R
    - `penguins$species` vs. `penguins[, "species"]`


## You want this plot

```{r, echo=FALSE}
penguins_long <- penguins |>
  select(species, sex, body_mass_g, bill_length_mm, bill_depth_mm) |> 
  pivot_longer(cols = -c(species, sex, body_mass_g),
               names_to = "bill_measure",
               values_to = "length") |> 
  drop_na()

ggplot(penguins_long, aes(x = body_mass_g, y = length, color = species)) +
  geom_point(size = 3) +
  scale_colour_viridis_d() +
  facet_grid(bill_measure ~ sex, scales = "free_y")
```


## You need

- `species`
- `sex`
- `body_mass_g`
- `bill_length_mm`
- `bill_depth_mm`

Turn `bill_length_mm` and `bill_depth_mm` into a new column "bill_measure" and values to a column called "length"


## `pivot_longer()`

```{r}
penguins_long <- penguins |>
  select(species, sex, body_mass_g, bill_length_mm, bill_depth_mm) |> 
  pivot_longer(cols = c(bill_length_mm, bill_depth_mm),
               names_to = "bill_measure",
               values_to = "length") |> 
  drop_na()
```

or

```{r}
penguins_long <- penguins |>
  select(species, sex, body_mass_g, bill_length_mm, bill_depth_mm) |> 
  pivot_longer(cols = -c(species, sex, body_mass_g),
               names_to = "bill_measure",
               values_to = "length") |> 
  drop_na()
```


## Long data

```{r}
penguins_long
```


## Plot

```{r, eval=FALSE}
ggplot(penguins_long, aes(x = body_mass_g, y = length, color = species)) +
  geom_point(size = 3) +
  scale_colour_viridis_d() +
  facet_grid(bill_measure ~ sex, scales = "free_y")
```


## Plot

```{r, eval=TRUE, fig.height=4}
ggplot(penguins_long, aes(x = body_mass_g, y = length, color = species)) +
  geom_point(size = 3) +
  scale_colour_viridis_d() +
  facet_grid(bill_measure ~ sex, scales = "free_y")
```


## Edit values

```{r}
penguins_long <- penguins_long |> 
  mutate(bill_measure = str_remove(bill_measure, "_mm"),
         bill_measure = str_remove(bill_measure, "bill_"))

head(penguins_long)
```


## `pivot_wider()`

Be careful:

```{r}
penguins_long |> 
  pivot_wider(id_cols = c(species, sex, body_mass_g),
              names_from = bill_measure, values_from = length)
```


## What happened?

`species`, `sex`, and `body_mass_g` don't uniquely identify new rows

```{r}
penguins_long |> 
  group_by(species, sex, body_mass_g) |> 
  tally()
```


## Tidyverse: joins

> Could you go over mutating joins?

> A review of the different join methods and how to select one.

> I would like to get explanation again on how the code for joining two datasets work and how can we specify in the code what we need; for example if we want only one column from df1 to merge it from only one column from df2. Or if we wouldn't want all observations/rows in the new merged set.


## Tidyverse: joins

Always joining two tibbles/data.frames.

What rows do you want to keep?

- `left_join(x, y)`: includes all rows in x.
- `right_join(x, y)`: includes all rows in y.
- `inner_join(x, y)`: includes all rows in x *and* y.
- `full_join(x, y)`: includes all rows in x *or* y.


## Joining

You also have data about the penguins' islands:

```{r}
island_data
```


## Which way to join?

1. Penguin data into island data
2. Island data into penguin data


## Keys

```{r}
intersect(colnames(penguins), colnames(island_data))
```


## `left_join()`

```{r}
left_join(penguins, island_data)
```


## Tidyverse: summarize, mutate, etc.

> I think I understand the difference between the mutate() and transmute() functions but, just to be clear, mutate() adds your new calculated variable on to your dataframe you've specified and keeps your original variables as well while transmute() only returns the new variable while eliminating or modifying the original variable you acted on as well?



## Making new variables

```{r}
penguins <- penguins |> 
  mutate(log_bill_length = log10(bill_length_mm),
         log_bill_depth = log10(bill_depth_mm))

str(penguins)
```


## Making new variables

```{r}
penguins$log_body_mass <- log10(penguins$body_mass_g)

str(penguins)
```


## `group_by()` and `summarize()`

1. Split the data into some set of subgroups
2. Apply some function(s) to create new variable(s)
3. Recombine the sets

- Means by species
- Means by species and sex
- Means by species, sex, and island


## Summarizing {.smaller}

```{r}
penguins |> 
  group_by(species, sex, island) |> 
  summarize(mean_log_mass = mean(log_body_mass),
            mean_log_bill_length = mean(log_bill_length),
            .groups = "drop")
```


## What happened? {.smaller}

- Some `sex` coded as `NA`

```{r}
penguins |> 
  drop_na(sex) |> 
  group_by(species, sex, island) |> 
  summarize(mean_log_mass = mean(log_body_mass),
            mean_log_bill_length = mean(log_bill_length),
            .groups = "drop")
```


## Data Visualizations

> What should one consider when deciding which plot to use for a given data set? Based on the graphs, would it be easy to identify if we used the incorrect type of distribution and what would that look like?


> In ggplot, how and why does assigning 'color = Species' works? Does it plot by the species or does it give it a color?

> For ggplot, is there a general rule for what goes into the aes() argument and what doesn't? Specifically for the geom additions (geom_point, geom_density, etc.)?


## Data Visualizations

> PS 4: Create a density plot for #3 and #6 above on the same plot. First create a single data frame with both sets and a column identifying each group.

> How to clean up the scatterplots and make them less noisy and more legible.

> Can you go over more plot manipulation please? (ggplot, boxplots, color manipulations, grouping, and more)


## Working with aesthetics

```{r, echo=FALSE}
penguins <- penguins |> 
  drop_na(body_mass_g)
```

```{r, fig.height=4}
ggplot(penguins, aes(body_mass_g, fill = species)) +
  geom_density()
```


## Working with aesthetics

```{r, fig.height=4}
ggplot(penguins, aes(body_mass_g, fill = species)) +
  geom_density(alpha = 0.5)
```


## Working with aesthetics

```{r, fig.height=4}
penguins <- penguins |> 
  mutate(species_alpha = case_when(
    species == "Adelie" ~ 1,
    species == "Chinstrap" ~ 0.5,
    species == "Gentoo" ~ 0.25
  ))
penguins |> select(species, species_alpha) |> slice_sample(n = 10)
```


## Working with aesthetics

```{r, fig.height=4}
ggplot(penguins, aes(body_mass_g, fill = species,
                     alpha = species_alpha)) +
  geom_density()
```


## Working with aesthetics

```{r, fig.height=4, message=FALSE}
library(ggridges)
ggplot(penguins, aes(x = body_mass_g, y = species, fill = species)) +
  geom_density_ridges(alpha = 0.5)
```


## Working with aesthetics

```{r, fig.height=4}
ggplot(penguins, aes(body_mass_g, color = species, fill = species)) +
  geom_histogram(bins = 30, alpha = 0.5)
```


## Working with aesthetics

```{r, fig.height=4}
ggplot(penguins, aes(log_bill_length, log_bill_depth, color = species,
                     size = log_body_mass)) +
  geom_point()
```


## Working with aesthetics

- color
- shape
- size
- linetype
- fill
- alpha
- text parameters

All are context-specific


## Probability

> One more slow explanation of conditional probability can't hurt. I think I just about understand it, but I want to really try and follow along.

> Could you go over an example similar to the cancer example in Problem Set 4? I am still struggling with interpreting Bayes' Rule. I understand how to set them up, but I am still working on interpreting what the question is asking!

> Can we briefly go over the prostate cancer example from Problem Set 4 - specifically how to solve it efficiently using R?

> I would like to go over the probability formula we used in unit 4. I feel like I still struggle with where to put each variable.

> I wouldn't mind another example of Bayes' Rule. I understand the premise but would like more practice with it.


## Temperature dependent sex determination

<center>
<img src="https://i.imgur.com/GBXvrf9.jpg" width="70%" />
</center>


## Temperature dependent sex determination

Above the critical temperature ($T_c$)

- $Pr[Female] = 0.8$
- $Pr[Male] = 0.2$

Below the critical temperature ($not~T_c$)

- $Pr[Female] = 0.5$
- $Pr[Male] = 0.5$


## How to *preferentially* collect female eggs?

You want to collect an egg from a nest and estimate what the temperature was in that nest when sex was determined.

- You want to preferentially collect from nests with large numbers of females
- The temperature now is not necessarily what it was (so you can't use a thermometer)

What is the probability that the nest was above $T_c$, given that you have collected a female egg?


## Variables

- $Pr[Female | T_c] = 0.8$
- $Pr[Female | not~T_c] = 0.5$


## Bayes' rule

$$Pr[A | B] = \frac{Pr[B | A] \cdot Pr[A]}{Pr[B]}$$

We want: *probability of $T_c$ given that we have observed a $Female$*

$$Pr[T_c | Female]$$

So:

- $A$ is $T_c$
- $B$ is $Female$


## Bayes' rule

$$Pr[T_c | Female] = \frac{Pr[Female | T_c] \cdot Pr[T_c]}{Pr[Female]}$$

We have:

- $Pr[Female | T_c] = 0.8$

We need:

- $Pr[T_c]$
- $Pr[Female]$


## Good distribution for $Pr[T_c]$?

Without any additional information about the distribution of $T_c$ among nests:

$$Pr[T_c] = 0.5$$

There is equal probability that a nest is above $T_c$ or below.


## Conditional probability

<center>
<img src="https://i.imgur.com/ViEcXg3.jpg" width="50%" />
</center>

$Pr[Female]$ is the sum of the two paths to Female.


## Bayes' rule

$$Pr[T_c | Female] = \frac{Pr[Female | T_c] \cdot Pr[T_c]}{Pr[Female]}$$

We have:

- $Pr[Female | T_c] = 0.8$
- $Pr[T_c] = 0.5$

We need:

$$Pr[Female] = Pr[Female | T_c] \cdot Pr[T_c] + $$
$$Pr[Female | not~ T_c] \cdot Pr[not~T_c]$$


## Bayes' rule

We need:

$$Pr[Female] = Pr[Female | T_c] \cdot Pr[T_c] + $$
$$Pr[Female | not~ T_c] \cdot Pr[not~T_c]$$

So:

$$Pr[Female] = 0.8 \cdot 0.5 + 0.5 \cdot 0.5$$
$$= 0.4 + 0.25$$
$$= 0.65$$

## Bayes' rule

$$Pr[T_c | Female] = \frac{Pr[Female | T_c] \cdot Pr[T_c]}{Pr[Female]}$$

$$Pr[T_c | Female] = \frac{0.8 \cdot 0.5}{0.65} = \frac{0.40}{0.65} = 0.62$$


## Bayes' rule

<center>
<img src="https://i.imgur.com/xJQzoB5.jpg" width="100%" />
</center>


## Probability

> How do you correctly identify true positives, false positives, true negatives, and false negatives based on the wording provided? Additionally, how does this relate to sensitivity and specificity?


## Probability

<center>
<img src="https://i.imgur.com/TdyYkUY.jpg" width="60%" />
</center>

- Sensitivity = [a/(a+c)] × 100 = True Positive *Proportion*
- Specificity = [d/(b+d)] × 100 = True Negative *Proportion*
- Positive predictive value(PPV) = [a/(a+b)] × 100
- Negative predictive value(NPV) = [d/(c+d)] × 100.

From: https://doi.org/10.3389/fpubh.2017.00307


