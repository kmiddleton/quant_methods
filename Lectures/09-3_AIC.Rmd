---
title: "Akaike Information Criteria"
subtitle: "Quantitative Methods in Life Sciences"
author: 'Elizabeth King and Kevin Middleton'
output:
  ioslides_presentation:
    fig_width: 8
    css: styles.css
csl: evolution.csl
bibliography: Multivariate.bib
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(cowplot)
library(readxl)
library(lmtest)
library(nlme)
library(forcats)

load("lrtmodels.Rda")
```

## Tradeoff in model specification

> "Overfitting: fitting is easy; prediction is hard. Future data will not be exactly like past data, and so any model that is unaware of this fact tends to make worse predictions than it could. So if we wish to make good predictions, we cannot judge our models simply on how well they fit our data. **Information criteria** provide estimates of predictive accuracy, rather than merely fit. So they compare models where it matters." [@McElreath2015-no]

## Kullback-Leibler information

**No model represents the true process that generated the outcomes.**

**Information** is the distance between a proposed model and reality

  - Information lost when trying to approximate the true model
  - Amount of "surprise" when a model predicts new data

K-L information doesn't aid directly in model evaluation (what is the true model?)

## Estimation of K-L information

Hirotugu Akaike ("Ah-ka-ee-kay") [-@Akaike1974-iw]

- Maximized log-likelihood could be used to estimate the *expected* K-L divergence between the candidate model and the true model.

<center>
<img src="https://i.imgur.com/WLVjbKW.jpg" width="40%" />
</center>

## Akaike's Information Criterion

"An Information Criterion": AIC is proportional to the *relative* K-L information of a model:

$$\mbox{AIC} = -2 \log\left(\mathcal{L}(\theta | \mbox{data})\right) + 2 k$$

where $\log\left(\mathcal{L}(\theta | \mbox{data})\right)$ is the maximized log-likelihood for the parameters $\theta$ given data.

- $-2$ comes in "for historical reasons" having to do with the $\chi^2$ distribution.

## Calculating AIC

log-likelihood for the intercept only (overall mean) model for the naked mole rats data:

```{r}
logLik(fm1)
-2 * as.numeric(logLik(fm1)) + 2 * 2
```

df = 2 because the mean and standard deviation are estimated.

## AIC

- AIC is a measure of the *lack* of model fit
    - Smaller AIC is better
- No notion of "significance".
    - Comparison is the key
- Negative twice the log-likelihood + 2 X *number of estimated parameters*
    - Penalization of models with large number of estimated parameters, because they will always fit the observed data better
    - Parsimony as a side-effect

## AIC in practice

- AIC was defined for large sample sizes

AICc adapts AIC for small samples

- AICc is asymptotic with AIC for large samples but less biased for small *n*

$$\mbox{AICc} = -2 \log\left(\mathcal{L}(\theta | \mbox{data})\right) + 2 k + \frac{2k(k+1)}{n - k - 1}$$

- Added "parameter" $\rightarrow$ 0 as $n \rightarrow \infty$
- Use AICc except when n/k > ~40 (see Burnham and Anderson)

## Comparing models with AIC (AICc)

1. Fit a set of candidate models (hypotheses)
1. Rank models according to AIC
1. Find the model with the lowest AIC
1. $\Delta$AIC is the value of AIC~lowest~ - AIC~model~

## Comparing models with AIC (AICc)

Rules of thumb:

- $\Delta$AIC $\leq$ 2: Substantial support
- $\leq$ 4 $\Delta$AIC $\leq$ 7: Considerably less support
- $\Delta$AIC $\geq$ 10: very little support

In practice:

- $\Delta$AIC < 4: Equally well supported

**This does not mean that the model you have ranked highest is a good model for the data in an absolute sense.**

## Akaike weights: evidence ratios

Back-transforming the logged likelihoods allows us to standardize AICs:

$$w_i = \frac{e^{-\Delta_i / 2}}{\sum_{r = 1}^R e^{-\Delta_r / 2}}$$

$w$ is a rescaled AIC on a scale of 0 $\rightarrow$ 1, giving the probability of a model actually being the best K-L model among *R* models.

- Still conditional on the data and the models
    - Maybe a better model is not in the sample of models

## Working with AIC

AIC is built-in to R:

```{r}
AIC(fm1)
```

AICc is not:

```{r}
library(AICcmodavg)
AICc(fm1)
```

Get in the habit of using AICc.

## AIC Tables

`AICcmodavg` function `aictab` for model comparison:

```{r}
aictab(cand.set = list(fm1, fm2, fm3, fm4, fm5, fm6))
```

## Return to some previous models

Use AICc to compare:

1. Maximum likelihood example
1. Rat weight gain
1. Limb lengths
1. Squid size
1. Species richness
1. Orthodontic growth

## Maximum likelihood example

```{r}
set.seed(4)
n <- 30
X <- rnorm(n, mean = 10, sd = 1)
Y <- 2.3 * X + rnorm(n, mean = 1, sd = 1)
fm_0 <- lm(Y ~ 1)       # Intercept (mean) only
(ll_0 <- logLik(fm_0))
fm_1 <- lm(Y ~ X)       # Intercept and slope
(ll_1 <- logLik(fm_1))
```

## Maximum likelihood example

Likelihood ratio test:

```{r message=FALSE}
library(lmtest)
lrtest(fm_0, fm_1)
```

## Maximum likelihood example {.smaller}

```{r}
AICc(fm_0) # Intercept only
AICc(fm_1) # Intercept and slope
aictab(cand.set = list(fm_0, fm_1),
       modnames = c("Intercept Only", "OLS"))
```

## Rat weight gain

```{r}
data("weightgain", package = "HSAUR3")

# Source only
fm_source <- lm(weightgain ~ source, data = weightgain)

# Type only
fm_type <- lm(weightgain ~ type, data = weightgain)

# Additive
fm_add <- lm(weightgain ~ source + type, data = weightgain)

# Factorial
fm_factorial <- lm(weightgain ~ source * type, data = weightgain)
```

## Rat weight gain

```{r}
aictab(list(fm_source, fm_type, fm_add, fm_factorial),
       modnames = c("Source", "Type", "Source + Type",
                    "Source * Type"))
```

## Limb lengths

```{r message = FALSE}
M <- read_csv("../data/Limb_Lengths.csv")
```

```{r echo=FALSE}
# FIXME
p1 <- ggplot(M, aes(left_limb, height)) + geom_point() +
  labs(x = "Limb Length (cm)", y = "Height (cm)") +
  ggtitle("Left Limb")
p2 <- ggplot(M, aes(right_limb, height)) + geom_point() +
  labs(x = "Limb Length (cm)", y = "Height (cm)") +
  ggtitle("Right Limb")
plot_grid(p1, p2, ncol = 2)
```

## Limb lengths

```{r}
# Left and right limb length
fm_LR <- lm(height ~ left_limb + right_limb, data = M)

# Left limb length only
fm_L <- lm(height ~ left_limb, data = M)
```

## Limb lengths

```{r}
aictab(list(fm_L, fm_LR), modnames = c("Left", "Left & Right"))
```

Models are both well supported, but *one is worthless*.

**AICc will not tell you if your model is good.**

## Squid size

```{r}
library(nlme)
S <- read_excel("../data/Squid.xlsx")
S <- S %>% mutate(Month = factor(Month))

# Linear model with interaction term
fm1 <- gls(Testis_Mass ~ DML * Month, data = S,
           method = "ML")

# Weighted regression
fm2 <- gls(Testis_Mass ~ DML * Month, data = S,
           weights = varPower(form = ~ DML | Month),
           method = "ML")
```

Note: using maximum likelihood here (`ML`), rather than restricted maximum likelihood (`REML`).

## Squid size

```{r}
aictab(list(fm1, fm2), modnames = c("Linear model", "Weighted"))
```

## Intertidal species richness

```{r}
RIKZ <- read_excel("../data/RIKZ.xlsx")
RIKZ <- RIKZ %>% mutate(Beach = factor(Beach))

fm_mixed_1 <- lme(Richness ~ NAP, random = ~ 1 | Beach, data = RIKZ,
                  method = "ML")
fm_mixed_2 <- lme(Richness ~ NAP, random = ~ NAP | Beach, data = RIKZ,
                  method = "ML",
                  control = list(opt = 'optim'))
```

- Switching `fm_mixed_2` to use a different optimizer, so the model will converge.

## Intertidal species richness

```{r}
AICc(fm_mixed_1) # random = ~ 1 | Beach
AICc(fm_mixed_2) # random = ~ NAP | Beach
```

## Intertidal species richness

```{r}
aictab(list(fm_mixed_1, fm_mixed_2),
       modnames = c("Random intercept", "Random int. & slope"))
```

## Orthodontic growth

```{r}
O <- read_excel("../data/Ortho.xlsx")
O <- O %>% mutate(Subject = factor(Subject),
                  Sex = factor(Sex))

# Intercepts per Subject
fm1 <- lme(Distance ~ Sex + Age, random = ~ 1 | Subject, 
           method = "ML",
           data = O)

# Intercepts and slopes per Subject
fm2 <- lme(Distance ~ Sex + Age, random = ~ Age | Subject,
           method = "ML",
           data = O)
```

## Orthodontic growth

```{r}
aictab(list(fm1, fm2),
       modnames = c("1 | Subject", "Age | Subject"))
```

## PS 08 Zooplankton

```{r message = FALSE, fig.height=3}
M <- read_csv("../data/Zooplankton.csv") %>% 
  mutate(Treatment = factor(Treatment),
         Treatment = fct_relevel(Treatment,
                                 "control", "low", "high"),
         Block = factor(Block))
M %>% 
  ggplot(aes(x = Treatment, y = Zooplankton, color = Block)) +
  geom_point()
```

## PS 08 Zooplankton

Model without `Block`, assumes all block means are equal:

```{r}
fm <- lm(Zooplankton ~ Treatment, M)
```

Model with `Block`, allows each block to have its own mean:

```{r}
fm_hier <- lm(Zooplankton ~ Treatment + Block, M)
```

## PS 08 Zooplankton

```{r}
aictab(list(fm, fm_hier), modnames = c("Non-hierarchical", "Block"))
```

## Note about model comparison with hierarchical models

This is a nuanced business:

- http://glmm.wikidot.com/faq


## General approach

1. Define hypotheses (models)
1. Fit using maximum likelihood methods (`lm()`, `gls()`, `lme()`, etc.). Note: not `REML` for hierarchical models.
1. Calculate AICc for each.
1. Sort by AICc.
1. Calculate $\Delta$AICc.
1. Models with $\Delta$AICc within ~4 of the best are all roughly equivalent
1. Decide what to do.
    - Describe multiple models
    - Compare Akaike weights

## Quiz 09-3

Lecture 09-4

## References
