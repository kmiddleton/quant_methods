---
title: "Applications of Inference Frameworks: More Basics"
subtitle: "Quantitative Methods in Life Sciences"
author: 'Elizabeth King and Kevin Middleton'
output:
  ioslides_presentation:
    fig_width: 8
    css: styles.css
csl: evolution.csl
bibliography: Multivariate.bib
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(cowplot)
```


## Readings

- Curran-Everett [-@Curran-Everett2009-zz]: Explorations in statistics: confidence intervals. *AJP: Advances in Physiology Education* 2: 87-90.

## Models

- Comparing models will require covering a few more basics
    - Concepts of central tendency
    - Concepts of spread
    - Deviations & sums of squares
    - Introduction to confidence intervals

## Measures of central tendency (location)

The value around which the distribution is centered

1. Mean
1. Median
1. Mode (most common value)

## Mean

Sample (arithmetic) mean:

$$\bar{Y} = \frac{\sum^n_{i=1}Y_i}{n}$$

The term "mean" is preferred to "average". The arithmetic mean is one kind of average, but there are others (as there are other types of means).

- One argument: "Average" is a statistic determined by an arithmetic procedure. "Mean" is a parameter.

## Median

The median is the central measurement of a sample (the 50th percentile and the 0.50 quantile). If $n$ is even, then the median is the mean of the two middle observations.

```{r}
undulation_rate <- c(0.9, 1.2, 1.2, 1.3, 1.4, 1.4, 1.6, 2.0)
median(undulation_rate)
```

## Mean vs. Median

Number of lateral plates (plates) in threespine sticklebacks (*Gasterosteus aculeatus*) with three different *Ectodysplasin* genotypes (mm, Mm, and MM).

<center>
<img src="https://i.imgur.com/Xr68AKa.jpg" width="75%" />
</center>

## Mean vs. Median

```{r echo=FALSE, message=FALSE}
SticklebackPlates <- read_csv("../data/Stickleback_Plates.csv")
```

```{r}
glimpse(SticklebackPlates)
```

## Mean vs. Median

```{r echo=FALSE, message=FALSE}
ggplot(SticklebackPlates, aes(x = plates)) +
  geom_histogram(bins = 30) +
  facet_grid(genotype ~ .) +
  xlab("Number of Lateral Body Plates") +
  ylab("Count")
```

## Mean vs. Median

```{r}
SticklebackPlates %>% group_by(genotype) %>% 
  summarize(mean_plate = mean(plates),
            median_plate = median(plates))
```

## Mean is sensitive to extreme values

```{r echo=FALSE, message=FALSE}
M <- SticklebackPlates %>% group_by(genotype) %>% 
  summarize(Mean = mean(plates),
            Median = median(plates)) %>% 
  gather(Value, x, -genotype)

ggplot(SticklebackPlates, aes(x = plates, group = genotype)) +
  geom_histogram(bins = 30) +
  geom_vline(data = M, aes(xintercept = x, color = Value),
             size = 2) +
  scale_color_manual(values = c("red", "blue")) +
  facet_grid(genotype ~ .) +
  xlab("Number of Lateral Body Plates") +
  ylab("Count")
```

## When might you substitute the median for the mean? | (As a measure of central tendency)

## Why don't we always use the median?

## Measures of spread

- A measure of how much variation is present in a distribution around its center
- How widely scattered the observations are

## Percentiles and quantiles

The $X$th **percentile** of a sample is the value below which $X\%$ of the observations lie. Percentiles are reported as percent.

 **Quantile** = Percentile / 100%. The range of quantiles is $0 \rightarrow 1$.

```{r}
xx <- rnorm(100000)
quantile(xx, 0.84)
quantile(xx, 0.975)
```

## Quartiles and interquartile range

*Quartiles*

- Divide a set of data into quarters
- Minimum, maximum, 25th and 75th percentiles

*Interquartile range*

- Difference between the first and third quartiles

## Boxplots

Different variations, but the most standard recipe is:

1. Median = center line
2. Box = IQR (25th to 75th percentiles)
3. Whiskers at 1.5 X 25th and 75th percentiles
4. Dots for anything outside 1.5 X 25th and 75th percentiles

## Boxplots

```{r echo=TRUE, fig.height = 3.5}
ggplot(SticklebackPlates, aes(x = genotype, y = plates)) +
  geom_boxplot()
```

## Raw data as an alternative to boxplots

When the number of observations is small, just show the raw data as points.

```{r eval=FALSE}
ggplot(SticklebackPlates, aes(x = genotype, y = plates)) +
  geom_point()
```

`x = genotype` maps the x position to the categorical variable genotype. `geom_point()` adds the points.

## Raw data as an alternative to boxplots

```{r echo=FALSE}
ggplot(SticklebackPlates, aes(x = genotype, y = plates)) +
  geom_point()
```

## Raw data as an alternative to boxplots

Add a little jitter on the x axis to keep from overplotting.

```{r eval=FALSE}
ggplot(SticklebackPlates, aes(x = genotype, y = plates)) +
  geom_point(position = position_jitter(width = 0.2))
```

## Raw data as an alternative to boxplots

Add a little jitter on the x axis to keep from overplotting.

```{r echo=FALSE}
ggplot(SticklebackPlates, aes(x = genotype, y = plates)) +
  geom_point(position = position_jitter(width = 0.2))
```

## Deviates

Lots of statistics have their basis in the deviation of an observation from a mean.

<center>
<img src="https://i.imgur.com/FxGzm7g.png" width="50%" />
</center>

The $i$th deviate is the difference of that observation and the sample mean:

$$
\textrm{Deviate}_i = Y_i - \bar{Y}
$$

We would like to have a single number to summarize the deviates for a sample.

## Sum of squares

Deviates are most often squared and summed:

$$
SS = \sum \left(Y_i - \bar{Y}\right)^2
$$

1. Why squared?
1. What does the sum of squares represent?

## Mean deviates

This is why we don't use the mean absolute deviation:

<center>
<img src="https://i.imgur.com/grGq9PZ.png" width="75%" />
</center>

Absolute value wouldn't capture the greater variability in the right image.

## Sample variance

Sum of squares standardized by one minus the sample size ($n - 1$):

$$
s^2 = \frac{\sum \left(Y_i - \bar{Y}\right)^2}{n - 1}
$$

- Mean squared deviation of the observations from the mean.
- Measures the dispersion of a distribution away from the sample mean.

## Sample standard deviation

$$
s = \sqrt{\frac{\sum \left(Y_i - \bar{Y}\right)^2}{n - 1}}
$$

- Square root of the sample variance.
- Think of $s$ as the "mean" for deviation.
- About 68% of the observations are $\pm 1$ standard deviation from the mean.

- When sample size is not low, the sample variance ($s^2$) is an *unbiased estimator* of the population variance ($\sigma^2$), though the calculation is a little different (divide by $n$ rather than $n − 1$) See [explanation of $n$ vs. $n-1$](http://stats.stackexchange.com/q/3931/597) 


## Standard error of the sample mean

$$SE_{\bar{Y}} = \frac{s}{\sqrt{n}}$$

Means are always reported with standard errors (or standard deviations).

- **Standard deviation** quantifies scatter — how much the values vary from one another and does not change predictably as you collect more data.
- **Standard error** of the mean quantifies how precisely you know the population mean. It takes into account both the value of $s$ and the sample size. Always decreases with larger sample size.

## Standard error of the sample mean

```{r}
SEM <- function(x) {sd(x) / sqrt(length(x))}

SticklebackPlates %>% 
  group_by(genotype) %>% 
  summarise_all(SEM)
  
```

## Raw data with summary stats

```{r pt_errbar, eval=FALSE}
ggplot(SticklebackPlates, aes(x = genotype, y = plates)) +
  geom_point(position = position_jitter(width = 0.2), alpha = 0.5) +
  stat_summary(fun.y = mean, geom = "point", size = 3, color = "red") + 
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.1,
               color = "red", size = 1)
```

## Boxplot and raw data

```{r pt_errbar2, ref.label="pt_errbar", echo=FALSE}
```

## Confidence intervals

> A confidence interval is a range that we expect, with some level of conﬁdence, to include the true value of a population parameter such as the mean. [@Curran-Everett2009-zz]

Our calculation is based on our expectation from sampling the true population distribution repeatedly. Let's try these: 

- [Sampling](http://www.zoology.ubc.ca/~whitlock/kingfisher/SamplingNormal.htm)
- [Confidence Intervals](http://www.zoology.ubc.ca/~whitlock/kingfisher/CIMean.htm)


## Confidence intervals

The 95% confidence interval for a mean can be estimated by the sample mean ± 2 \times $SE_{\bar{Y}}$.

- This is a reasonable approximation.
- We'll cover the exact calculation (what you would use in press) later



## Confidence intervals

```{r}
y_bar <- mean(undulation_rate)
se_y <- sd(undulation_rate) / sqrt(length(undulation_rate))
lower <- y_bar - 2 * se_y
upper <- y_bar + 2 * se_y
```

We are 95% confident that the true mean lies between `r round(lower, 2)` and `r round(upper, 2)`.

Mean undulation rate was `r round(y_bar, 2)` Hz ($n$ = `r length(undulation_rate)`; 95% CI = `r round(lower, 2)` - `r round(upper, 2)` Hz).

## Coefficient of variation

Coefficient of variation represents the standard deviation as a percentage of the mean. Elephant mass has an inherently higher standard deviation than mouse mass.

$$
CV = 100\% \times \frac{s}{\bar{Y}}
$$

- Can be used as a general indicator of the amount of variability in a sample.
- Can also be used to (cautiously) compare variables that are not measured in the same units (e.g., basal metabolic rate to ear area).

## Coefficient of variation

```{r}
CV <- 100 * sd(undulation_rate) / mean(undulation_rate)
CV
```

The coefficient of variation of undulation rate was `r round(CV, 1)`%.

## Quiz 05-1

Complete quiz 05-1.

Watch lecture 05-2 on Canvas.

## References
