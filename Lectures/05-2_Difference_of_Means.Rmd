---
title: "Applications of Inference Frameworks: Difference of Means"
subtitle: "Quantitative Methods in Life Sciences"
author: 'Elizabeth King and Kevin Middleton'
date: 'Last updated: `r Sys.Date()`'
output:
  ioslides_presentation:
    fig_width: 8
    css: styles.css
csl: evolution.csl
bibliography: Multivariate.bib
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(cowplot)
library(rethinking)
library(latex2exp)
library(wesanderson)
```

## Horned lizard predation

<center>
<img src="http://ichef.bbci.co.uk/wwfeatures/wm/live/624_351/images/live/p0/37/4s/p0374s1q.jpg" width="100%" />
</center>

## Horned lizard predation

```{r message=FALSE}
HL <- read_csv("../data/HornedLizards.csv")
glimpse(HL)
HL %>% group_by(group) %>% tally()
```

## Horned lizard predation

```{r echo=FALSE, warning=FALSE}
HL %>% 
  ggplot(aes(horn_length)) +
  geom_histogram(bins = 30) +
  facet_grid(group ~ .) +
  labs(x = "Horn Length (mm)", y = "Count")
```

## Summarize

```{r}
HL %>% group_by(group) %>% 
  summarize(horn_mean = mean(horn_length),
            horn_sd = sd(horn_length))
sum(!complete.cases(HL))
```

## Summarize

Drop rows with any `NA`s:

```{r}
HL <- HL %>% drop_na()
```

Summarize:

```{r}
HL %>% group_by(group) %>% 
  summarize(horn_mean = mean(horn_length),
            horn_sd = sd(horn_length))
```

## Are the means different?

Horn length in live horned lizards: `r round(mean(HL$horn_length[HL$group == "alive"]), 2)` mm

Horn length in dead horned lizards: `r round(mean(HL$horn_length[HL$group == "dead"]), 2)` mm

Imagine you collected 100 live horned lizards and randomly assigned 50 to each of two groups. Do you think they would have the same mean horn length? How different do you think the means would be? Think about how the variability among individual horn length measurements would affect your intuition here.

> The first principle is that you must not fool yourself â€“ and you are the easiest person to fool. -Feynman

## How large of a difference do we expect to see from sampling error?

<div class="columns-2">
<center>
<img src="http://3.bp.blogspot.com/_6dWrARvFLx4/TFo-Vo1cdyI/AAAAAAAABqg/ITJBYWI8q3s/s1600/horned+lizard+4.JPG" width="100%" />
<br />
<br />
<br />
</center>

- Imagine a distribution of horn lengths for a population of horned lizards (mean = 24, sd = 3)
- Randomly catch two groups of $n = 50$ from this population
- How different are they?
</div>

## How large of a difference do we expect to see from sampling error?

```{r}
set.seed(883231)
mu.horn <- 24 # mean
sd.horn <- 3 # standard deviation
n.iter <- 10000 # number of iterations
n.samp <- 50 # number in each sample
sim.diff <- data_frame(dd = numeric(length = n.iter)) # vector for output  

for (zz in 1:n.iter) {
  s1 <- rnorm(n.samp, mu.horn, sd.horn) # sample 1
  s2 <- rnorm(n.samp, mu.horn, sd.horn) # sample 2
  sim.diff[zz, 'dd'] <- mean(s1) - mean(s2) # difference in means
}
```

## How large of a difference do we expect to see from sampling error?

<div class="columns-2">

```{r message=FALSE, fig.width=3.5, fig.height=3.5, echo=FALSE}
ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30) +
  labs(x = "Difference of Means", y = "Count")
```

- Imagine a distribution of horn lengths for a population of horned lizards (mean = 24, sd = 3)
- Randomly catch two groups of $n = 50$ from this population
- How different are they?
</div>

## How large of a difference do we expect to see from sampling error?

<div class="columns-2">

```{r message=FALSE, fig.width=3.5, fig.height=3.5, echo=FALSE}
HL %>% 
  ggplot(aes(horn_length)) +
  geom_histogram(bins = 30) +
  facet_grid(group ~ .) +
  labs(x = "Horn Length (mm)", y = "Count")
```

Horn length in live horned lizards: `r round(mean(HL$horn_length[HL$group == "alive"]), 2)` mm

Horn length in dead horned lizards: `r round(mean(HL$horn_length[HL$group == "dead"]), 2)` mm

Difference: `r round(mean(HL$horn_length[HL$group == "alive"]), 2) - round(mean(HL$horn_length[HL$group == "dead"]), 2)`

Are the means different?
</div>

## How large of a difference do we expect to see from sampling error?

```{r message=FALSE, fig.height=3.5, echo=FALSE}
p1 <- ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30) +
  labs(x = "Difference of Means", y = "Count")

HL_mean <- HL %>% group_by(group) %>% 
  summarize(Mean = mean(horn_length)) %>% 
  gather(Value, x, -group)

p2 <- HL %>% 
  ggplot(aes(horn_length)) +
  geom_histogram(bins = 30) +
  geom_vline(data = HL_mean, aes(xintercept = x, color = Value),
             size = 2) +
  facet_grid(group ~ .) +
  labs(x = "Horn Length (mm)", y = "Count") +
  theme(legend.position = "none")

plot_grid(p2, p1, ncol = 2)
```

Difference: `r round(mean(HL$horn_length[HL$group == "alive"]), 2) - round(mean(HL$horn_length[HL$group == "dead"]), 2)`

## Frameworks for inference

1. Analytical
2. Maximum likelihood
3. Resampling
4. Bayesian

## Analytical: *t*-test

```{r t_plot, message=FALSE, fig.height=2.5, echo=FALSE, warning=FALSE}
x <- seq(-3, 3, by = 0.001)

sim <- data_frame(df = c(2, 10, 50)) %>%
  group_by(df) %>%
  do(data_frame(x = x, y = dt(x, .$df))) %>%
  mutate(Parameters = paste0("df = ", df)) %>%
  ungroup() %>%
  mutate(Parameters = factor(Parameters, levels = unique(Parameters)))

norm <- data_frame(
  x = x,
  y = dnorm(x, 0, 1)
)

pal <- wes_palette("Moonrise3", 3, type = "discrete")

ggplot() +
  geom_line(data = sim, aes(x, y, color = Parameters), size = 1.5) +
  geom_line(data = norm, aes(x, y)) +
  scale_color_manual(values = pal, name = "Degrees of\nFreedom") +
  labs(x = "x", y = "Relative Likelihood") +
  theme(legend.position = c(0.9, 0.75))
```

- Test statistic based on means, standard deviations, and sample size 
- Follows a *t* distribution
- Like a normal distribution that accounts for sample size
- We won't derive the *t* distribution

</div>

## *t*-test

```{r}
t.test(horn_length ~ group, data = HL, var.equal = TRUE)
```

## ML Comparison

*Model 1*: Data drawn from one distribution

*Model 2*: Data drawn from distributions with 2 different means

Compare the models with a likelihood ratio (Bayes Factor):

$$BF = \frac{\mathcal{L}[Model~2]}{\mathcal{L}[Model~1]}$$

## Data drawn from one distribution

Single sample variance:

$$s^2 = \frac{1}{n - 1}\left(\sum^{n_1}_{i=1} \left(y_i - \bar{y}\right)^2\right)$$

Shared variance:

$$\hat{\sigma}^2_1 = \frac{1}{n_1 + n_2}\left(\sum^{n_1}_{i=1}\left(y_{1i} - \bar{\bar{y}}\right)^2 +  \sum^{n_2}_{i=1} \left(y_{2i} - \bar{\bar{y}}\right)^2 \right)$$

where $\bar{\bar{y}}$ is the grand mean.

## Data drawn from one distribution

Likelihood of the $y$s being drawn from the same distribution:

$$\mathcal{L}\left(\hat{\mu}, \hat{\sigma}^2_1|y\right) = \frac{1}{\left(2\pi \hat{\sigma}^2_1\right)^\left(\frac{n_1 + n_2}{2}\right)}e^{\left(-\frac{n_1 + n_2}{2}\right)}$$

## Data drawn from distributions with 2 different means

Assume equal variances but different means.

$$\hat{\sigma}^2_2 = \frac{1}{n_1 + n_2}\left(\sum^{n_1}_{i=1}\left(y_{1i} - \bar{y}_1\right)^2 +  \sum^{n_2}_{i=1} \left(y_{2i} - \bar{y}_2\right)^2 \right)$$

$$\mathcal{L}\left(\hat{\mu}_1, \hat{\mu}_2, \hat{\sigma}^2_2|y\right) = \frac{1}{\left(2\pi \hat{\sigma}^2_2\right)^\left(\frac{n_1 + n_2}{2}\right)}e^{\left(-\frac{n_1 + n_2}{2}\right)}$$

## ML Comparison

*Model 1*: Data drawn from one distribution

*Model 2*: Data drawn from distributions with 2 different means

Compare the models with a likelihood ratio (Bayes Factor):

$$BF = \frac{\mathcal{L}[Model~2]}{\mathcal{L}[Model~1]} = \frac{\mathcal{L}\left(\hat{\mu}_1, \hat{\mu}_2, \hat{\sigma}^2_2|y\right)}{\mathcal{L}\left(\hat{\mu}, \hat{\sigma}^2_1|y\right)} = \left(\frac{\hat{\sigma}^2_2}{\hat{\sigma}^2_1}\right)^{-\frac{n_1 + n_2}{2}}$$

More in Problem Set 5.

## Resampled difference of means

```{r resampled_difference, cache=TRUE}
set.seed(8734)
reps <- 50000
diffs <- numeric(length = reps)

diffs[1] <- mean(HL$horn_length[HL$group == "alive"]) -
  mean(HL$horn_length[HL$group == "dead"])

for (i in 2:reps) {
  shuffle <- sample(HL$horn_length)
  diffs[i] <- mean(shuffle[HL$group == "alive"]) -
    mean(shuffle[HL$group == "dead"])
}
```

## Difference of means

```{r echo=FALSE}
data_frame(diffs) %>% 
  ggplot(aes(diffs)) + 
  geom_histogram(bins = 30) +
  geom_vline(xintercept = diffs[1], color = "red") +
  labs(x = "Difference (mm)", y = "Count")
```

## What proportion of randomized differences are equal to or more extreme than the observed?

```{r}
p <- sum(diffs[1] <= diffs) / length(diffs)
sprintf("%.5f", p)
sprintf("%.5f", 3 / 50000)
```

## Bayesian

Prepare data:

```{r message=FALSE}
HL <- read_csv("../data/HornedLizards.csv") %>% 
  drop_na() %>% 
  mutate(group = coerce_index(group)) %>% 
  as.data.frame()
str(HL)
```

`coerce_index(group)` converts factors into integers.

## Bayesian

```{r}
mean(HL$horn_length)
```

Prior for group means (alive, dead) ~  $\mathcal{N}(\mu = 23.9, \sigma = 5)$

- ~95% of probability lies between 13.9 and 33.9
- Estimate posterior distribution of each group simultaneously

```{r echo=FALSE, fig.height = 2}
data_frame(x = seq(10, 38, length = 100),
           y = dnorm(x, 23.9, 5)) %>% 
  ggplot(aes(x, y)) +
  geom_line() +
  labs(x = "Prior for Horn Length (mm)")
```


## Bayesian

```{r bayes_mean_2, cache=TRUE}
fm2 <- map2stan(
  alist(
    horn_length ~ dnorm(mu, sigma),
    mu <- a[group],
    a[group] ~ dnorm(23.9, 5),
    sigma ~ dcauchy(0, 2)
  ),
  data = HL,
  iter = 1e5, warmup = 1e3)
```

## Bayesian

```{r echo=FALSE}
plot(fm2)
```

## Bayesian posterior distributions

```{r echo=FALSE}
post <- extract.samples(fm2)
alive <- post$a[, 1]
dead <- post$a[, 2]

data_frame(alive, dead) %>%
  gather(group, horn) %>% 
  ggplot(aes(horn, color = group)) +
  geom_line(stat = "density", size = 1.5) +
  labs(x = "Horn Length (mm)", y = "Relative Likelihood")
```

## Bayesian summary

```{r}
precis(fm2, depth = 2, digits = 4)
HL %>% group_by(group) %>% 
  summarize(horn_mean = mean(horn_length),
            horn_sem = sd(horn_length) / sqrt(length(horn_length)))
```

## Bayesian credible interval

95% credible interval of difference:

```{r echo=FALSE, fig.height = 2}
diff <- alive - dead
hdint <- HPDI(diff)

data_frame(diff) %>% 
  ggplot(aes(diff)) +
  geom_line(stat = "density", size = 1.5) +
  geom_vline(xintercept = hdint[1], color = "lightblue", size = 1.5) +
  geom_vline(xintercept = hdint[2], color = "lightblue", size = 1.5) +
  labs(x = "Difference (alive - dead; mm)")
```

```{r}
HPDI(diff, prob = 0.95)
```

## Quiz 05-2

Complete quiz 05-2.

Watch lecture 05-3 on Canvas.
