---
title: "Hypothesis Testing"
subtitle: "Quantitative Methods in Life Sciences"
author: 'Elizabeth King, Kevin Middleton, and Lauren Sullivan'
output:
  ioslides_presentation:
    fig_width: 8
    css: styles.css
csl: evolution.csl
bibliography: Multivariate.bib
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(cowplot)
theme_set(theme_cowplot())
source("Shade_Distributions.R")
```

## Hypotheses

**Hypothesis**: a statement that can be either true or false

**Statistical hypothesis**: a hypothesis about about a parameter (or parameters) of a population or process

- Many statistical analyses have the goal of performing a hypothesis test.

**Three Frameworks** : Analytical, Maximum Likelihood, Bayesian


## Analytical

- Calculate test statistic
- Determine *P*-value (area under tail(s))

<div class="columns-2">

```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.025, 10,tail = "both")
```

```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.05, 10,tail = "upper")
```

</center>


## One sided or two-sided tests

Data will always be on one side of H~0~ or the other.

**One-sided test** ("one-tailed"):

- Appropriate when we have an *a priori* hypothesis of the direction of change

- You need justification and to be explicit about it, when you report a one-sided test.

**Two-sided test** ("two-tailed"):

- *Appropriate at all other times.*
- Multiply the one-sided *P* by 2.
    - Don't forget to do this.


## Analytical

- Calculate test statistic
- Determine *P*-value (area under tail(s))

<div class="columns-2">

```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.15, 10,tail = "both") +
  ggtitle("P = 0.3")
```

```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.005, 10,tail = "both") +
    ggtitle("P = 0.01")

```

</center>


## Maximum Likelihood

- Does a given model explain significantly more variation than a model with fewer parameters?

- Likelihood ratios
    - Likelihood of Model 2 (more parameters)/Likelihood of Model 1 (fewer parameters)
    - Follow a $\chi^2$ Distribution (*df* = difference in number of estimated parameters)

*Stay Tuned for Model Comparisons*


## Bayesian Inference

- Does the Credible Interval of a given parameter estimate encompass the value in question. e.g.,:
    -  Does the credible interval for the difference in means include zero?
    -  Does the credible interval for the parameter estimate include 98.6?


## Tests of arbitrary slopes and intercepts

$$t = \frac{b - \beta_{0}}{\mbox{SE}_{b}}$$

is a general equation that can be used to test any null hypothesized parameter estimate.

- $b$ is the parameter estimate, $\beta_0$ is the null hypothesized value (often and by default $\beta_0 = 0$)
- Analyses of allometry: the study of scaling relationships


## PanTHERIA: Database of mammal life history data

Data from Jones et al [-@Jones2009-vg]

```{r load_mammals, echo=FALSE, message=FALSE}
# Load mammals data
mammals <- read_delim("../data/mammals.txt", delim = "\t")
names(mammals) <- sub("^[0-9]*-[0-9]*_", "", names(mammals))
names(mammals) <- sub("MSW05_", "", names(mammals))
mammals <- mammals %>%
  dplyr::select(Order, Binomial, AdultBodyMass_g, 
                AdultForearmLen_mm)
names(mammals) <- gsub("([A-Z])", "_\\L\\1", names(mammals),
                       perl = TRUE)
names(mammals) <- gsub("^_", "", names(mammals),
                       perl = TRUE)
mammals[mammals == -999] <- NA
names(mammals)[names(mammals) == "binomial"] <- "species"

# Drop a bunch of incomplete cases
mammals <- mammals %>% drop_na()
names(mammals) <- c("Order", "Species", "Mass", "Forearm")
```

*AdultBodyMass_g*: Mass of adult (or age unspecified) live or freshly-killed specimens (excluding pregnant females) using captive, wild, provisioned, or unspecified populations; male, female, or sex unspecified individuals; primary, secondary, or extrapolated sources; all measures of central tendency; in all localities.

*AdultForearmLen_mm*: Total length from elbow to wrist of adult (or age unspecified) live, freshly-killed, or museum specimens using captive, wild, provisioned, or unspecified populations; male, female, or sex unspecified individuals; primary, secondary, or extrapolated sources; all measures of central tendency; in all localities.


## Examine the data

```{r}
glimpse(mammals)
```


## Preliminary plotting

```{r mammals_raw_plot, eval=TRUE, echo=FALSE}
ggplot(mammals, aes(x = Mass, y = Forearm, color = Order)) +
  geom_point() +
  labs(x = "Adult Body Mass (g)", y = "Adult Forearm Length (mm)")
```


## Drop the really large mammals

Observations:

1. Very few large mammals in the sample
1. "Large" mammals (> 5 kg) might have a different scaling pattern from the smaller ones (at least in the sample)
1. Only bats remain

```{r}
# Drop all rows with Mass >= 5000 g
mammals <- mammals %>% filter(Mass <= 5000)
```


## Replot

```{r echo=FALSE}
ggplot(mammals, aes(x = Mass, y = Forearm)) +
  geom_point() +
  labs(x = "Adult Body Mass (g)", y = "Adult Forearm Length (mm)")
```


## Replot

```{r echo=FALSE}
ggplot(mammals, aes(x = Mass, y = Forearm)) +
  geom_point() +
  geom_smooth(formula = y ~ x, se = FALSE, method = "lm") +
  labs(x = "Adult Body Mass (g)", y = "Adult Forearm Length (mm)")
```


## Scaling relationships

> "In biology, constancy in shape with change in size is termed *isometric growth* (or *isometry*), the usual null hypothesis in morphological scaling studies." LaBarbera [-@LaBarbera1989-hn]

Lengths are linearly proportional to lengths:

$$L_1 \propto L_2$$

Area is proportional to a length squared:

$$A \propto L^2$$

Volume (mass) is proportional to a length cubed:

$$V \propto L^3$$


## Log transformation

The power law relationship:

$$Y = \theta_0~M^{\theta_1}$$

Can be linearized by logging (natural, base-10) both sides of the equation:

$$\log{Y} = \log{\theta_0} + \theta_1 \log{M}$$


## Plotting on log-log scale

```{r mammals_log_plot, eval=FALSE}
ggplot(mammals, aes(x = Mass, y = Forearm)) +
  geom_point() +
  xlab("log-10 Adult Body Mass (g)") +
  ylab("log-10 Adult Forearm Length (mm)") +
  scale_x_log10() +
  scale_y_log10()
```


## Plotting on log-log scale

```{r ref.label="mammals_log_plot", echo=FALSE}
```


## Caution about working in log space

In this case log~10~:

> "It is probably difficult, for example, to appreciate that points quite close together, such as with log values of 4.90 and 4.60, are the difference on a linear scale between about 79,000 and 40,000." Smith [-@Smith1984-gp]


## Log-transformation

```{r}
mammals <- mammals %>%
  mutate(log_Mass = log10(Mass),
         log_Forearm = log10(Forearm))
glimpse(mammals)
```


## OLS regression on logged data {.smaller}

```{r}
fm <- lm(log_Forearm ~ log_Mass, data = mammals)
summary(fm)
```


## Test of a specific slope

Isometric slope $= \theta_1 = Mass^{1/3}$

$$t = \frac{b - \theta_1}{SE_{\theta_1}}$$

```
            Estimate Std. Error t value Pr(>|t|)
log_Mass    0.307339   0.004427   69.42   <2e-16
```

```{r}
(t_value <- (0.307339 - (1 / 3)) / 0.004427)
2 * pt(t_value, df = 658 - 2)
```


## Caveats

Think about your power to detect an effect.

- Context for "not significant" results.
- Context for "significant" results.

Think about error in measurement of Body Mass

- OLS regression assumes $x$ measured with no error.

Think about independence of observations

- Bats are phylogenetically closely related


## Types of errors and statistical power

|               | Reject H~0~    | Fail to reject H~0~   |
|--------------:|:--------------:|:---------------------:|
|H~0~ is true   | Type I error   | *Correct*             |
|H~0~ is false  | *Correct*      | Type II error         |

Type I error occurs when:

- *P* is small by *random chance*, given that $\alpha$ is chosen ahead of the test

Type II error probability depends on:

- The value of $\alpha$
- How "wrong" H~0~ is


## Power

- Probability that a random sample will lead to a rejection of H~0~
- Dependent on how different the truth is from the null hypothesis
- Inversely related to type II errors
    - High power $\rightarrow$ low type II errors
    - Low power $\rightarrow$ high type II errors
- Power analysis will come later in the course


## Controversy

Philosophical and practical problems have been raised since the 1960's.

- In 1986, the *American Journal of Public Health* told all researchers wanting to publish in the journal that he would no longer accept results based on *P*-values (and then backed down 2 years later)
- *Basic and Applied Social Psychology* banned *P*-values in 2015
- In 2016, the American Statistical Association published a "Statement on *P*-Values: Context, Process, and Purpose" which critiqued the (mis)use of *P*-values.


## History

- K. Pearson: Pearson's correlation, $\chi^2$, eugenics
- Fisher: Fisher's exact test, "null hypothesis", ANOVA (*F*), eugenics
- Gosset: *t* distribution, Student's *t*-tests, Guinness
- Neyman and E. Pearson: "null hypothesis" testing, confidence intervals, decision theory

The modern idea is traced to these statisticians, but has been warped into something different:

- Test statistics (*F*, *t*, $\chi^2$) applied to Neyman-Pearson "null hypotheses"
- H~0~ becomes a straw man hypothesis of no difference or no effect


## Problem with *P*-values

- Originally an informal concept that got co-opted for what became null hypothesis significance testing (NHST)
- Apparent objectivity but actually arbitrary and dependent on the data collected and not collected
- Experimental biases (experimenter introduced, sample size)
- Science-wide publication bias


## Science-wide publication bias {.smaller}

Corollaries proposed by Ioannidis [-@Ioannidis2005-od]:

1. The smaller the studies conducted in a scientific field, the less likely the research findings are to be true.
2. The smaller the effect sizes in a scientific field, the less likely the research findings are to be true.
3. The greater the number and the lesser the selection of tested relationships in a scientific field, the less likely the research findings are to be true.
4. The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true.
5. The greater the financial and other interests and prejudices in a scientific field, the less likely the research findings are to be true.
6. The hotter a scientific field (with more scientific teams involved), the less likely the research findings are to be true.


## Alternative suggested approaches

Preregistration of experimental design and planned analysis

1. Report parameter estimates and confidence intervals only 
1. Model selection

Either of above could be done in a frequentist, likelihood or Bayesian framework


## References {.references}
