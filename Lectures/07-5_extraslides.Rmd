---
title: "Hypothesis Testing"
subtitle: "Quantitative Methods in Life Sciences"
author: 'Elizabeth King, Kevin Middleton, and Lauren Sullivan'
output:
  ioslides_presentation:
    fig_width: 8
    css: styles.css
csl: evolution.csl
bibliography: Multivariate.bib
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(cowplot)
theme_set(theme_cowplot())
source("https://raw.githubusercontent.com/kmiddleton/quant_methods/master/Lectures/Shade_Distributions.R")

options(pillar.sigfig = 4)
```

## Hypotheses

**Hypothesis**: a statement that can be either true or false

**Statistical hypothesis**: a hypothesis about about a parameter (or parameters) of a population or process

- Many statistical analyses have the goal of performing a hypothesis test.

**Three Frameworks** : Analytical, Maximum Likelihood, Bayesian


## Analytical

- Calculate test statistic
- Determine *P*-value (area under tail(s))

<div class="columns-2">

```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.025, 10,tail = "both")
```

```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.05, 10,tail = "upper")
```

</center>


## One sided or two-sided tests

Data will always be on one side of H~0~ or the other.

**One-sided test** ("one-tailed"):

- Appropriate when we have an *a priori* hypothesis of the direction of change

- You need justification and to be explicit about it, when you report a one-sided test.

**Two-sided test** ("two-tailed"):

- *Appropriate at all other times.*
- Multiply the one-sided *P* by 2.
    - Don't forget to do this.


## Analytical

- Calculate test statistic
- Determine *P*-value (area under tail(s))

<div class="columns-2">

```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.15, 10,tail = "both") +
  ggtitle("P = 0.3")
```

```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.005, 10,tail = "both") +
    ggtitle("P = 0.01")

```

</center>


## Maximum Likelihood

```{r, echo=FALSE}
set.seed(4)
n <- 30
X <- rnorm(n, mean = 10, sd = 1)
Y <- 2.3 * X + rnorm(n, mean = 1, sd = 1)
M <- data.frame(X, Y)

log_lik <- function(theta_1, X, Y){
  Y_bar <- mean(Y)
  X_bar <- mean(X)
  theta_0 <- Y_bar - theta_1 * X_bar
  Y_hat <- theta_0 + theta_1 * X
  var_hat <- sum((Y - Y_hat) ^ 2) / (length(Y))
  sd_hat <- sqrt(var_hat)
  liks_Y <- dnorm(Y, mean = Y_hat, sd = sd_hat, log = TRUE)
  return(sum(liks_Y))
}

theta_1 <- seq(0, 5.5, by = 0.001)
lls <- numeric(length(theta_1))
for (ii in 1:length(theta_1)) {
  lls[ii] <- log_lik(theta_1[ii], X, Y)
}

D <- tibble(theta_1, model_likelihood = lls)

# Location of maximum log-likelihood
max_ll <- lls[which.max(lls)]

# Slope at maximum log-likelihood
theta_1_hat <- theta_1[which.max(lls)]

p <- ggplot() +
  geom_line(data = D, aes(x = theta_1, y = model_likelihood), size = 2) +
  geom_point(data = tibble(theta_1_hat, max_ll),
             aes(x = theta_1_hat, y = max_ll), color = "red", size = 4) +
  labs(y = "Model likelihood")
```


What are the bounds of parameter estimates at the desired quantiles of the likelihood?

```{r, echo=FALSE}
print(p)
```


## Maximum Likelihood

Likelihood difference between the model (1) with a slope and (2) without a slope follows a $\chi^2$ distribution with $df = 1$ (for the slope).

Critical value:

```{r}
qchisq(p = 0.95, df = 1)
```

We need the interval around the maximum log-likelihood within 1/2 of the critical value.

```{r}
(crit <- qchisq(p = 0.95, df = 1) / 2)
```


## Maximum Likelihood

```{r, echo=FALSE}
p +
  geom_hline(yintercept = max_ll - crit, color = "blue", size = 2)
```


## Maximum Likelihood

```{r}
CI <- D %>% 
  filter(model_likelihood >= max_ll - crit) %>% 
  summarize(lower_theta_1 = min(theta_1),
            upper_theta_1 = max(theta_1))
CI
```


## Maximum Likelihood

```{r, echo=FALSE}
p +
  geom_hline(yintercept = max_ll - crit, color = "blue", size = 2) +
  geom_vline(xintercept = CI$lower_theta_1, color = "red", size = 2) +
  geom_vline(xintercept = CI$upper_theta_1, color = "red", size = 2)
```


## Maximum Likelihood

```{r}
fm <- lm(Y ~ X)
confint(fm, "X")
CI
```


## Bayesian Inference

- Does the Credible Interval of a given parameter estimate encompass the value in question. e.g.,:
    -  Does the credible interval for the difference in means include zero?
    -  Does the credible interval for the parameter estimate include 98.6?


## Tests of arbitrary slopes and intercepts

$$t = \frac{\theta - \theta_{null}}{\mbox{SE}_{\theta}}$$

is a general equation that can be used to test any null hypothesized parameter estimate.

- $\theta$ is the parameter estimate
- $\theta_{null}$ is the null hypothesized value
    - often and by default $\theta_{null} = 0$
- Analyses of allometry: the study of scaling relationships


## PanTHERIA: Database of mammal life history data

Data from Jones et al [-@Jones2009-vg]

```{r load_mammals, echo=FALSE, message=FALSE}
# Load mammals data
mammals <- read_delim("../data/mammals.txt", delim = "\t")
names(mammals) <- sub("^[0-9]*-[0-9]*_", "", names(mammals))
names(mammals) <- sub("MSW05_", "", names(mammals))
mammals <- mammals %>%
  dplyr::select(Order, Binomial, AdultBodyMass_g, 
                AdultForearmLen_mm)
names(mammals) <- gsub("([A-Z])", "_\\L\\1", names(mammals),
                       perl = TRUE)
names(mammals) <- gsub("^_", "", names(mammals),
                       perl = TRUE)
mammals[mammals == -999] <- NA
names(mammals)[names(mammals) == "binomial"] <- "species"

# Drop a bunch of incomplete cases
mammals <- mammals %>% drop_na()
names(mammals) <- c("Order", "Species", "Mass", "Forearm")
```

*AdultBodyMass_g*: Mass of adult (or age unspecified) live or freshly-killed specimens (excluding pregnant females) using captive, wild, provisioned, or unspecified populations; male, female, or sex unspecified individuals; primary, secondary, or extrapolated sources; all measures of central tendency; in all localities.

*AdultForearmLen_mm*: Total length from elbow to wrist of adult (or age unspecified) live, freshly-killed, or museum specimens using captive, wild, provisioned, or unspecified populations; male, female, or sex unspecified individuals; primary, secondary, or extrapolated sources; all measures of central tendency; in all localities.


## Examine the data

```{r}
glimpse(mammals)
```


## Preliminary plotting

```{r mammals_raw_plot, eval=TRUE, echo=FALSE}
ggplot(mammals, aes(x = Mass, y = Forearm, color = Order)) +
  geom_point() +
  labs(x = "Adult Body Mass (g)", y = "Adult Forearm Length (mm)")
```


## Drop the really large mammals

Observations:

1. Very few large mammals in the sample
1. "Large" mammals (> 5 kg) might have a different scaling pattern from the smaller ones (at least in the sample)
1. Only bats remain

```{r}
# Drop all rows with Mass >= 5000 g
mammals <- mammals %>% filter(Mass <= 5000)
```


## Replot

```{r echo=FALSE}
ggplot(mammals, aes(x = Mass, y = Forearm)) +
  geom_point() +
  labs(x = "Adult Body Mass (g)", y = "Adult Forearm Length (mm)")
```


## Replot

```{r echo=FALSE}
ggplot(mammals, aes(x = Mass, y = Forearm)) +
  geom_point() +
  geom_smooth(formula = y ~ x, se = FALSE, method = "lm") +
  labs(x = "Adult Body Mass (g)", y = "Adult Forearm Length (mm)")
```


## Scaling relationships

> "In biology, constancy in shape with change in size is termed *isometric growth* (or *isometry*), the usual null hypothesis in morphological scaling studies." LaBarbera [-@LaBarbera1989-hn]

Lengths are linearly proportional to lengths:

$$L_1 \propto L_2$$

Area is proportional to a length squared:

$$A \propto L^2$$

Volume (mass) is proportional to a length cubed:

$$V \propto L^3$$


## Log transformation

The power law relationship:

$$Y = \theta_0~M^{\theta_1}$$

Can be linearized by logging (natural, base-10) both sides of the equation:

$$\log{Y} = \log{\theta_0} + \theta_1 \log{M}$$


## Plotting on log-log scale

```{r mammals_log_plot, eval=FALSE}
ggplot(mammals, aes(x = Mass, y = Forearm)) +
  geom_point() +
  labs(x = "log-10 Adult Body Mass (g)",
       y = "log-10 Adult Forearm Length (mm)") +
  scale_x_log10() +
  scale_y_log10()
```


## Plotting on log-log scale

```{r ref.label="mammals_log_plot", echo=FALSE}
```


## Caution about working in log space

In this case log~10~:

> "It is probably difficult, for example, to appreciate that points quite close together, such as with log values of 4.90 and 4.60, are the difference on a linear scale between about 79,000 and 40,000." Smith [-@Smith1984-gp]


## Log-transformation

```{r}
mammals <- mammals %>%
  mutate(log_Mass = log10(Mass),
         log_Forearm = log10(Forearm))
glimpse(mammals)
```


## OLS regression on logged data {.smaller}

```{r}
fm <- lm(log_Forearm ~ log_Mass, data = mammals)
summary(fm)
```


## Test of a specific slope

Isometric slope $= \theta_{null} = Mass^{1/3}$

$$t = \frac{\theta_1 - \theta_{null}}{SE_{\theta_1}}$$

```
            Estimate Std. Error t value Pr(>|t|)
log_Mass    0.307339   0.004427   69.42   <2e-16
```

```{r}
(t_value <- (0.307339 - (1 / 3)) / 0.004427)
2 * pt(t_value, df = 658 - 2)
```


## Caveats

Think about your power to detect an effect.

- Context for "not significant" results.
- Context for "significant" results.

Think about error in measurement of Body Mass

- OLS regression assumes $x$ measured with no error.

Think about independence of observations

- Bats are phylogenetically closely related


## Types of errors and statistical power

|               | Reject H~0~    | Fail to reject H~0~   |
|--------------:|:--------------:|:---------------------:|
|H~0~ is true   | Type I error   | *Correct*             |
|H~0~ is false  | *Correct*      | Type II error         |

Type I error occurs when:

- *P* is small by *random chance*, given that $\alpha$ is chosen ahead of the test

Type II error probability depends on:

- The value of $\alpha$
- How "wrong" H~0~ is


## Power

- Probability that a random sample will lead to a rejection of H~0~
- Dependent on how different the truth is from the null hypothesis
- Inversely related to type II errors
    - High power $\rightarrow$ low type II errors
    - Low power $\rightarrow$ high type II errors
- Power analysis will come later in the course


## Controversy

Philosophical and practical problems have been raised since the 1960's.

- In 1986, the *American Journal of Public Health* told all researchers wanting to publish in the journal that he would no longer accept results based on *P*-values (and then backed down 2 years later)
- *Basic and Applied Social Psychology* banned *P*-values in 2015
- In 2016, the American Statistical Association published a "Statement on *P*-Values: Context, Process, and Purpose" which critiqued the (mis)use of *P*-values.


## History

- K. Pearson: Pearson's correlation, $\chi^2$, eugenics
- Fisher: Fisher's exact test, "null hypothesis", ANOVA (*F*), eugenics
- Gosset: *t* distribution, Student's *t*-tests, Guinness
- Neyman and E. Pearson: "null hypothesis" testing, confidence intervals, decision theory


## History

The modern idea is traced to these statisticians, but has been warped into something different:

- Test statistics ($F$, $t$, $\chi^2$) and Fisher's rule-of-thumb $P = 0.05$ applied to Neyman-Pearson "null hypotheses"
- H~0~ becomes a straw man hypothesis of no difference or no effect


## Problem with *P*-values

- Originally an informal concept that got co-opted for what became null hypothesis significance testing (NHST)
- Apparent objectivity but actually arbitrary and dependent on the data collected and not collected
- Experimental biases (experimenter introduced, sample size)
- Science-wide publication bias


## Science-wide publication bias {.smaller}

Corollaries proposed by Ioannidis [-@Ioannidis2005-od]:

1. The smaller the studies conducted in a scientific field, the less likely the research findings are to be true.
2. The smaller the effect sizes in a scientific field, the less likely the research findings are to be true.
3. The greater the number and the lesser the selection of tested relationships in a scientific field, the less likely the research findings are to be true.
4. The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true.
5. The greater the financial and other interests and prejudices in a scientific field, the less likely the research findings are to be true.
6. The hotter a scientific field (with more scientific teams involved), the less likely the research findings are to be true.


## Alternative suggested approaches

Preregistration of experimental design and planned analysis

1. Report parameter estimates and confidence intervals only 
1. Model selection

Either of above could be done in a frequentist, likelihood or Bayesian framework


## References {.references}
